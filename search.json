[{"title":"MYDB项目总结","url":"/2025/04/14/MYDB%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/","content":"MYDB1.为什么使用NIO，有哪些好处\n2.日志是怎么做的\n3.如何处理可见性\n​\t1）根据数据库不同的隔离级别来保证不同的可见性\n​\t2）读未提交：这时不对事务的可见性做任何处理，可能会导致脏读、不可重复读、幻读；\n​\t3）读提交：引入MVCC\n​\t\t在读提交隔离级别下如何判断一条记录是否对当前事务可见：​\t\t1）获取当前数据记录的xmin和xmax；\n​\t\t2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n​\t\t3）判断创建该数据记录的事务是否提交，如果已经提交，进一步进行判断，否则说明当前事务为完成，该数据记录对当前事务不可见；\n​\t\t4）如果创建该数据记录的事务已经提交，并且xmax不存在，说明该记录违背删除或者修改，该记录对当前事务可见；\n​\t\t5）如果xmax存在，并且不等于当前事务id，判断xmax事务是否已经提交，若xmax事务还未提交，说明该数据记录对当前版本仍然可见。\n​\t4）读未提交：同样引入MVCC\n​\t\t在可重复读隔离级别下如何判断一条记录是否对当前事务可见：\n​\t\t1）获取当前数据记录的xmin和xmax；\n​\t\t2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n​\t\t3）如果xmin事务已经提交，并且xmin &lt; xid，同时xmin事务已经提交，xmax不存在，说明该数据记录对当前事务可见；\n​\t\t4）如果事务xmax存在，并且xmax不等于xid，如果事务xmax还未提交，或这事务xmax是再当前事务开始后才开始的，又或是事务xmax还处在获活跃状态，说明该数据记录对当前事务是可见的。\n​\t5）串行化：使用两阶段锁，如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。\n4.ACID如何实现\n​\t1）原子性：项目中的事务分为活跃、提交和回滚三个状态，主要是通过对事务状态的保存来确保事务的原子性；\n​\t2）持久性：通过记录日志来保证数据库的持久性，以及事务提交时强制刷盘，保证数据已经写入磁盘中，一次来保证数据库的持久性；\n​\t3）一致性：通过实现其他三种性质来保证一致性；\n​\t4）隔离性：通过数据库中实现的MVCC来保证数据之间的隔离性。\n5.死锁如何处理\n​\t1）当一个事务请求获取某个资源时，首先会检查该资源是否已被其他事务持有。如果没有被持有，资源将直接分配给请求的事务。如果资源已被占用，事务将进入等待状态，并存储在相应的等待队列中。\n​\t2）在某些情况下，事务可能会由于等待时间过长而被回滚。通过后台线程定期检查每个事务的等待时间，并在超时时执行回滚操作。 超时检测与回滚机制的基本思想是：\n\n每个事务在获取资源时，如果资源被其他事务占用，则需要等待。\n为了避免长时间等待导致系统资源被锁住，我们为每个等待的事务设置一个超时时间（30S）。\n当检测到事务等待超时后，系统将回滚这个事务，并释放它占用的所有资源，从而避免死锁或资源饥饿。\n\n启动一个后台线程，定期检查每个事务的等待时间。如果超时，则执行回滚操作。\n6.存储和空间回收如何处理\n​\tMVCC的版本清理：若当前版本的事务ID已提交且无活跃事务引用，则可以清除该版本\n7.介绍下项目中的B+树\n8.SQL语句解析\n​\t1）将SQL语句解析为多个token，其中引号中的内容被当作一个token\n​\t2）根据SQL语句的第一个字段来执行不同的操作\n\n1.TM (Transaction Manager) 事务管理（1）XID 事务ID，每个事务对应一个ID\n（2）事务状态，active&#x2F;活跃，commited&#x2F;提交，aborted&#x2F;回滚\n（3）文件读写采用NIO，NIO与BIO的对比如下\n​\t\t阻塞与非阻塞\n\nBIO：在进行 I&#x2F;O 操作时，线程会被阻塞。比如在读取数据时，线程会一直等待直到数据完全读取完毕；在写入数据时，会一直等待直到数据全部写入。这种阻塞特性会导致线程在等待过程中无法进行其他工作，造成资源浪费。举例来说，一个服务器使用 BIO 处理多个客户端连接时，每个连接都需要一个独立的线程来处理，若某个客户端连接数据传输缓慢，会使对应线程长时间阻塞，影响系统整体性能。\nNIO：采用非阻塞模式，线程在进行 I&#x2F;O 操作时不会被阻塞，可以去执行其他任务。线程可以询问是否有数据准备好，若没有则可以继续执行其他代码，之后再回来检查。例如，服务器使用 NIO 时，一个线程可以处理多个客户端连接，当某个连接没有数据可读时，线程不会等待，而是去处理其他连接，提高了线程的利用率。\n\n​\t\t多路复用机制\n\nBIO：缺乏有效的多路复用机制，若要处理多个客户端连接，通常需要为每个连接创建一个独立的线程。线程的创建和销毁会带来较大的开销，并且过多的线程会导致系统资源竞争激烈，增加上下文切换的开销，降低系统性能。\nNIO：引入了选择器（Selector），它是 NIO 实现多路复用的核心。一个选择器可以同时监听多个通道（Channel）的事件，如读、写、连接等。线程可以通过选择器来轮询哪些通道有事件发生，然后对这些通道进行相应的处理。这样，一个线程就可以处理多个客户端连接，减少了线程的使用数量，降低了系统开销。\n\n​\t\t缓冲区与通道\n\nBIO：使用流（Stream）的方式进行数据传输，数据的读写是单向的，输入流只能读，输出流只能写。而且流的操作是基于字节或字符的，每次只能处理一个或多个字节 &#x2F; 字符，效率较低。\nNIO：采用缓冲区（Buffer）和通道（Channel）的方式进行数据传输。通道是双向的，可以同时进行读写操作，提高了数据传输的灵活性。缓冲区是一个连续的内存块，数据可以批量地从通道读取到缓冲区，或者从缓冲区写入到通道，减少了数据的复制次数，提高了数据传输的效率。\n\n（4）**begin()**方法，开启一个事务并将其设置为活跃状态，同时事务id计数器自增\n（5）updateXID()方法，更新事务状态，后面的commit() ,**abort()**方法就可以直接借助 updateXID() 方法实现\n（6）检查事务状态的三个方法 isActive(), isCommited(), isAborted()\n（7）静态方法create()，创建一个XID文件\n（8）静态方法open()，从一个已有的XID文件来创建TM\n\n2.DM (Data Manager) 数据管理（1）DM直接管理数据库DB文件和日志文件，具体职责如下：1）分页管理DB文件，并进行缓存；2）管理日志文件，保证数据库在发生错误时根据日志进行恢复；3）抽象DB文件为DataItem，提供给尚存使用，并提供缓存\n（2）引用计数法设计缓存，当计数为0时，直接从缓存中删除这个资源；同时，缓存满了之后应该直接报错。定义了一个抽象类：\nAbstractCache&lt;T&gt;/** * 当资源不在缓存时的获取行为 */protected abstract T getForCache(long key) throws Exception;/** * 当资源被驱逐时的写回行为 */protected abstract void releaseForCache(T obj);\n\n同时，为应对多线程并发场景，额外记录了哪些资源正在被读取，构造了以下三个数据结构：\nprivate HashMap&lt;Long, T&gt; cache;                     // 实际缓存的数据private HashMap&lt;Long, Integer&gt; references;          // 资源的引用个数private HashMap&lt;Long, Boolean&gt; getting;             // 正在被获取的资源\n\n因此在读取缓存时，首先进入死循环，一直尝试从缓存中获取数据，同时检查是否有其他线程正在使用这个数据；\n如果数据在缓存中，直接返回，同时引用计数+1；\n如果不在缓存中，首先在getting中对数据进行标记，表示其正在被使用，在用**getForCache(long key)**获取缓存。\n\n3.数据页的缓存与管理（1）DM向下将文件系统抽象成页面，每次对文件的读写都是以页面为单位的，同时缓存也是以页面为单位进行的，页面缓存存储在内存中。\n（2）数据页大小为8K，借用上一节已经实现的引用计数缓存框架进行缓存，数据页的数据结构如下：\npublic class PageImpl implements Page&#123;\tprivate int pageNumber;\t//页号    private byte[] data;\t//数据内容    private boolean ditry; \t//是否为脏页    private Lock lock;        private PageCache pc;&#125;\n\n（3）获取缓存getForCache(long key)，传入的参数为页号\nprotected Page getForCache(long key) throws Exception &#123;    int pgno = (int)key;    long offset = PageCacheImpl.pageOffset(pgno);    ByteBuffer buf = ByteBuffer.allocate(PAGE_SIZE);    fileLock.lock();    try &#123;        //通过偏移量获取文件开始读写的位置        fc.position(offset);        fc.read(buf);    &#125; catch(IOException e) &#123;        Panic.panic(e);    &#125;    fileLock.unlock();    return new PageImpl(pgno, buf.array(), this);&#125;private static long pageOffset(int pgno) &#123;    // 页号从 1 开始    return (pgno-1) * PAGE_SIZE;&#125;\n\n（4）驱逐页面releaseForCache(Page pg)，\nprotected void releaseForCache(Page pg) &#123;    if(pg.isDirty()) &#123;        flush(pg);        pg.setDirty(false);    &#125;&#125;private void flush(Page pg) &#123;    int pgno = pg.getPageNumber();    long offset = pageOffset(pgno);    fileLock.lock();    try &#123;        //将数据包装成页面        ByteBuffer buf = ByteBuffer.wrap(pg.getData());        //确定读写位置        fc.position(offset);        //写入缓存        fc.write(buf);        //刷回磁盘        fc.force(false);    &#125; catch(IOException e) &#123;        Panic.panic(e);    &#125; finally &#123;        fileLock.unlock();    &#125;&#125;\n\n（5）使用了一个AtomicInteger，记录当前打开的数据库文件有多少页。\n（6）同一条数据不允许跨页存储。\n（7）数据库的第一页用来做启动检查，具体原理是，每次启动数据库的时候，会生成一段随机字节，存储在 100 ~ 107 字节。在数据库正常关闭时，会将这串字节，拷贝到第一页的 108 ~ 115 字节。这样数据库在每次启动时，就会检查第一页两处的字节是否相同，以此来判断上一次是否正常关闭。如果是异常关闭，就需要执行数据的恢复流程。\n（8）对于普通页的管理与第一页不同。普通页面以一个 2字节无符号数开始，表示这一页的空闲指针，在写前读取空闲指针，并在写后更新空闲指针\n（9）**recoverInsert()和recoverUpdate()**用于在数据库崩溃后重新打开，在下一章中会用到\n\n4.日志文件和恢复策略（1）DM每次对数据文件进行操作时，都会记录一条日志到磁盘；数据库崩溃后，再次启动时可以根据日志内容恢复数据文件，保持其一致性。\n日志的二进制文件，按照如下的格式进行排布：\n[XChecksum][Log1][Log2][Log3]...[LogN][BadTail]\n\n其中 XChecksum 是一个四字节的整数，是对后续所有日志计算的校验和。Log1 ~ LogN 是常规的日志数据，BadTail 是在数据库崩溃时，没有来得及写完的日志数据，这个 BadTail 不一定存在。\n（2）每条日志的格式如下：\n[Size][Checksum][Data]\n\n（3）在打开一个日志文件时，需要首先校验日志文件的 XChecksum，并移除文件尾部可能存在的 BadTail，由于 BadTail 该条日志尚未写入完成，文件的校验和也就不会包含该日志的校验和，去掉 BadTail 即可保证日志文件的一致性。\n（4）向日志文件中写入文件时，先写入文件在更新文件的校验和，更新校验和时使用FileChannel的**force()**方法保证文件会被刷回磁盘\n（5）DM向上提供了两种操作：插入和更新，在进行插入和更新前，必须保证日志写入后，才能够对数据进行操作。\n对于两种数据操作，DM 记录的日志如下：\n\n(Ti, I, A, x)，表示事务 Ti 在 A 位置插入了一条数据 x\n(Ti, U, A, oldx, newx)，表示事务 Ti 将 A 位置的数据，从 oldx 更新成 newx\n\n如果不考虑并发的情况，那么在某一时刻，只可能有一个事务在操作数据库。日志会看起来像下面那样：\n(Ti, x, x), ..., (Ti, x, x), (Tj, x, x), ..., (Tj, x, x), (Tk, x, x), ..., (Tk, x, x)\n\n对于单线程，Ti、Tj 和 Tk 的日志永远不会相交。这种情况下利用日志恢复很简单，假设日志中最后一个事务是 Ti：\n\n对 Ti 之前所有的事务的日志，进行重做（redo）\n接着检查 Ti 的状态（XID 文件），如果 Ti 的状态是已完成（包括 committed 和 aborted），就将 Ti 重做，否则进行撤销（undo）\n\n接着，是如何对事务 T 进行 redo：\n\n正序扫描事务 T 的所有日志\n如果日志是插入操作 (Ti, I, A, x)，就将 x 重新插入 A 位置\n如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 newx\n\nundo 也很好理解：\n\n倒序扫描事务 T 的所有日志\n如果日志是插入操作 (Ti, I, A, x)，就将 A 位置的数据删除\n如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 oldx\n\n对于多线程：\n规定1：正在进行的事务，不会读取其他任何未提交的事务产生的数据。\n规定2：正在进行的事务，不会修改其他任何未提交的事务修改或产生的数据。\n\n5.页面索引与DM实现页面索引，缓存了每一页的空闲空间。用于在上层模块进行插入操作时，能够快速找到一个合适空间的页面，而无需从磁盘或者缓存中检查每一个页面的信息。\n\n6.记录的版本&amp;事务隔离（1）两阶段锁：如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。\n​\t2PL 确实保证了调度序列的可串行化，但是不可避免地导致了事务间的相互阻塞，甚至可能导致死锁。为了提高事务处理的效率，降低阻塞概率，实现了 MVCC。\n（2）MVCC：VM(版本管理)管理所有的数据项，并向上层提供数据记录的概念，上层模块通过VM操作数据记录。VM内部为每个数据记录维护了多个版本，每当上层模块对某个数据记录进行修改时，VM就会为这个记录创建一个新的版本。\n（3）一条数据记录中存储的数据格式如下：\n[XMIN] [XMAX] [DATA]\n\n（4）事务的隔离级别：\n读提交：防止级联回滚；实现读提交，为每个版本维护了两个变量，就是上面提到的 XMIN 和 XMAX：\n\nXMIN：创建该版本的事务编号\nXMAX：删除该版本的事务编号\n\nXMIN 应当在版本创建时填写，而 XMAX 则在版本被删除，或者有新版本出现时填写。XMAX 这个变量，也就解释了为什么 DM 层不提供删除操作，当想删除一个版本时，只需要设置其 XMAX，这样，这个版本对每一个 XMAX 之后的事务都是不可见的，也就等价于删除了。\n在读提交隔离级别下如何判断一条记录是否对当前事务可见：1）获取当前数据记录的xmin和xmax；\n2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n3）判断创建该数据记录的事务是否提交，如果已经提交，进一步进行判断，否则说明当前事务为完成，该数据记录对当前事务不可见；\n4）如果创建该数据记录的事务已经提交，并且xmax不存在，说明该记录违背删除或者修改，该记录对当前事务可见；\n5）如果xmax存在，并且不等于当前事务id，判断xmax事务是否已经提交，若xmax事务还未提交，说明该数据记录对当前版本仍然可见。\n可重复读：解决不可重复读的问题，即一个事务执行期间对同一个数据向多次读取得到不同的结果；\n为实现可重复读，规定当前事务运行时需要忽略：1）再本事务后开始的事务所更新的数据，通过比较事务ID实现；\n2）本事务开始时，还是活跃状态事务的数据，通过再当前事务开始时，记录下当前所有活跃的事务ID；重要：如果xmin也在这个活跃事务的集合中，这个数据也应当对当前事务不可见。\n在可重复读隔离级别下如何判断一条记录是否对当前事务可见：\n1）获取当前数据记录的xmin和xmax；\n2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n3）如果xmin事务已经提交，并且xmin &lt; xid，同时xmin事务已经提交，xmax不存在，说明该数据记录对当前事务可见；\n4）如果事务xmax存在，并且xmax不等于xid，如果事务xmax还未提交，或这事务xmax是再当前事务开始后才开始的，又或是事务xmax还处在获活跃状态，说明该数据记录对当前事务是可见的。\n\n7.死锁检测与VM实现（1）MVCC 的实现，使得 MYDB 在撤销或是回滚事务很简单：只需要将这个事务标记为 aborted 即可。根据前一章提到的可见性，每个事务都只能看到其他 committed 的事务所产生的数据，一个 aborted 事务产生的数据，就不会对其他事务产生任何影响了，也就相当于，这个事务不曾存在过。\n（2）版本跳跃问题：版本跳跃问题，考虑如下的情况，假设 X 最初只有 x0 版本，T1 和 T2 都是可重复读的隔离级别：\nT1 beginT2 beginR1(X) // T1读取x0R2(X) // T2读取x0U1(X) // T1将X更新到x1T1 commitU2(X) // T2将X更新到x2T2 commit\n\n​\t这种情况实际运行起来是没问题的，但是逻辑上不太正确。T1 将 X 从 x0 更新为了 x1，这是没错的。但是 T2 则是将 X 从 x0 更新成了 x2，跳过了 x1 版本。\n​\t读提交是允许版本跳跃的，而可重复读则是不允许版本跳跃的。解决版本跳跃的思路也很简单：如果 Ti 需要修改 X，而 X 已经被 Ti 不可见的事务 Tj 修改了，那么要求 Ti 回滚。\n​\t事务Ti不可见事务Tj有两种情况：\n​\t1）Ti的事务id小于Tj的事务id，即Tj是在Ti开始后才开始的\n​\t2）事务Ti开始时，Tj仍处于活跃状态\n","tags":["MySQL"]},{"title":"随笔","url":"/2025/04/14/%E9%9A%8F%E7%AC%94/","content":"因为去年电脑重做了系统，博客上的文件并没有存下来，所以今天重新搭建了我的博客。回想22年的时候，YH手把手教我和DL搭建博客，那时候好像在看天书一样，什么都不懂，注册github账号时，少打了一个字母，applepiglet变成了applepiget，也行吧。还是像刚学计算机时一样——你好，世界。\n"}]