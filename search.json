[{"title":"MYDB项目总结","url":"/2025/04/14/MYDB%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/","content":"MYDB1.为什么使用NIO，有哪些好处\n2.日志是怎么做的\n3.如何处理可见性\n​\t1）根据数据库不同的隔离级别来保证不同的可见性\n​\t2）读未提交：这时不对事务的可见性做任何处理，可能会导致脏读、不可重复读、幻读；\n​\t3）读提交：引入MVCC\n​\t\t在读提交隔离级别下如何判断一条记录是否对当前事务可见：​\t\t1）获取当前数据记录的xmin和xmax；\n​\t\t2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n​\t\t3）判断创建该数据记录的事务是否提交，如果已经提交，进一步进行判断，否则说明当前事务为完成，该数据记录对当前事务不可见；\n​\t\t4）如果创建该数据记录的事务已经提交，并且xmax不存在，说明该记录违背删除或者修改，该记录对当前事务可见；\n​\t\t5）如果xmax存在，并且不等于当前事务id，判断xmax事务是否已经提交，若xmax事务还未提交，说明该数据记录对当前版本仍然可见。\n​\t4）读未提交：同样引入MVCC\n​\t\t在可重复读隔离级别下如何判断一条记录是否对当前事务可见：\n​\t\t1）获取当前数据记录的xmin和xmax；\n​\t\t2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n​\t\t3）如果xmin事务已经提交，并且xmin &lt; xid，同时xmin事务已经提交，xmax不存在，说明该数据记录对当前事务可见；\n​\t\t4）如果事务xmax存在，并且xmax不等于xid，如果事务xmax还未提交，或这事务xmax是再当前事务开始后才开始的，又或是事务xmax还处在获活跃状态，说明该数据记录对当前事务是可见的。\n​\t5）串行化：使用两阶段锁，如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。\n4.ACID如何实现\n​\t1）原子性：项目中的事务分为活跃、提交和回滚三个状态，主要是通过对事务状态的保存来确保事务的原子性；\n​\t2）持久性：通过记录日志来保证数据库的持久性，以及事务提交时强制刷盘，保证数据已经写入磁盘中，一次来保证数据库的持久性；\n​\t3）一致性：通过实现其他三种性质来保证一致性；\n​\t4）隔离性：通过数据库中实现的MVCC来保证数据之间的隔离性。\n5.死锁如何处理\n​\t1）当一个事务请求获取某个资源时，首先会检查该资源是否已被其他事务持有。如果没有被持有，资源将直接分配给请求的事务。如果资源已被占用，事务将进入等待状态，并存储在相应的等待队列中。\n​\t2）在某些情况下，事务可能会由于等待时间过长而被回滚。通过后台线程定期检查每个事务的等待时间，并在超时时执行回滚操作。 超时检测与回滚机制的基本思想是：\n\n每个事务在获取资源时，如果资源被其他事务占用，则需要等待。\n为了避免长时间等待导致系统资源被锁住，我们为每个等待的事务设置一个超时时间（30S）。\n当检测到事务等待超时后，系统将回滚这个事务，并释放它占用的所有资源，从而避免死锁或资源饥饿。\n\n启动一个后台线程，定期检查每个事务的等待时间。如果超时，则执行回滚操作。\n6.存储和空间回收如何处理\n​\tMVCC的版本清理：若当前版本的事务ID已提交且无活跃事务引用，则可以清除该版本\n7.介绍下项目中的B+树\n8.SQL语句解析\n​\t1）将SQL语句解析为多个token，其中引号中的内容被当作一个token\n​\t2）根据SQL语句的第一个字段来执行不同的操作\n\n1.TM (Transaction Manager) 事务管理（1）XID 事务ID，每个事务对应一个ID\n（2）事务状态，active&#x2F;活跃，commited&#x2F;提交，aborted&#x2F;回滚\n（3）文件读写采用NIO，NIO与BIO的对比如下\n​\t\t阻塞与非阻塞\n\nBIO：在进行 I&#x2F;O 操作时，线程会被阻塞。比如在读取数据时，线程会一直等待直到数据完全读取完毕；在写入数据时，会一直等待直到数据全部写入。这种阻塞特性会导致线程在等待过程中无法进行其他工作，造成资源浪费。举例来说，一个服务器使用 BIO 处理多个客户端连接时，每个连接都需要一个独立的线程来处理，若某个客户端连接数据传输缓慢，会使对应线程长时间阻塞，影响系统整体性能。\nNIO：采用非阻塞模式，线程在进行 I&#x2F;O 操作时不会被阻塞，可以去执行其他任务。线程可以询问是否有数据准备好，若没有则可以继续执行其他代码，之后再回来检查。例如，服务器使用 NIO 时，一个线程可以处理多个客户端连接，当某个连接没有数据可读时，线程不会等待，而是去处理其他连接，提高了线程的利用率。\n\n​\t\t多路复用机制\n\nBIO：缺乏有效的多路复用机制，若要处理多个客户端连接，通常需要为每个连接创建一个独立的线程。线程的创建和销毁会带来较大的开销，并且过多的线程会导致系统资源竞争激烈，增加上下文切换的开销，降低系统性能。\nNIO：引入了选择器（Selector），它是 NIO 实现多路复用的核心。一个选择器可以同时监听多个通道（Channel）的事件，如读、写、连接等。线程可以通过选择器来轮询哪些通道有事件发生，然后对这些通道进行相应的处理。这样，一个线程就可以处理多个客户端连接，减少了线程的使用数量，降低了系统开销。\n\n​\t\t缓冲区与通道\n\nBIO：使用流（Stream）的方式进行数据传输，数据的读写是单向的，输入流只能读，输出流只能写。而且流的操作是基于字节或字符的，每次只能处理一个或多个字节 &#x2F; 字符，效率较低。\nNIO：采用缓冲区（Buffer）和通道（Channel）的方式进行数据传输。通道是双向的，可以同时进行读写操作，提高了数据传输的灵活性。缓冲区是一个连续的内存块，数据可以批量地从通道读取到缓冲区，或者从缓冲区写入到通道，减少了数据的复制次数，提高了数据传输的效率。\n\n（4）**begin()**方法，开启一个事务并将其设置为活跃状态，同时事务id计数器自增\n（5）updateXID()方法，更新事务状态，后面的commit() ,**abort()**方法就可以直接借助 updateXID() 方法实现\n（6）检查事务状态的三个方法 isActive(), isCommited(), isAborted()\n（7）静态方法create()，创建一个XID文件\n（8）静态方法open()，从一个已有的XID文件来创建TM\n\n2.DM (Data Manager) 数据管理（1）DM直接管理数据库DB文件和日志文件，具体职责如下：1）分页管理DB文件，并进行缓存；2）管理日志文件，保证数据库在发生错误时根据日志进行恢复；3）抽象DB文件为DataItem，提供给尚存使用，并提供缓存\n（2）引用计数法设计缓存，当计数为0时，直接从缓存中删除这个资源；同时，缓存满了之后应该直接报错。定义了一个抽象类：\nAbstractCache&lt;T&gt;/** * 当资源不在缓存时的获取行为 */protected abstract T getForCache(long key) throws Exception;/** * 当资源被驱逐时的写回行为 */protected abstract void releaseForCache(T obj);\n\n同时，为应对多线程并发场景，额外记录了哪些资源正在被读取，构造了以下三个数据结构：\nprivate HashMap&lt;Long, T&gt; cache;                     // 实际缓存的数据private HashMap&lt;Long, Integer&gt; references;          // 资源的引用个数private HashMap&lt;Long, Boolean&gt; getting;             // 正在被获取的资源\n\n因此在读取缓存时，首先进入死循环，一直尝试从缓存中获取数据，同时检查是否有其他线程正在使用这个数据；\n如果数据在缓存中，直接返回，同时引用计数+1；\n如果不在缓存中，首先在getting中对数据进行标记，表示其正在被使用，在用**getForCache(long key)**获取缓存。\n\n3.数据页的缓存与管理（1）DM向下将文件系统抽象成页面，每次对文件的读写都是以页面为单位的，同时缓存也是以页面为单位进行的，页面缓存存储在内存中。\n（2）数据页大小为8K，借用上一节已经实现的引用计数缓存框架进行缓存，数据页的数据结构如下：\npublic class PageImpl implements Page&#123;\tprivate int pageNumber;\t//页号    private byte[] data;\t//数据内容    private boolean ditry; \t//是否为脏页    private Lock lock;        private PageCache pc;&#125;\n\n（3）获取缓存getForCache(long key)，传入的参数为页号\nprotected Page getForCache(long key) throws Exception &#123;    int pgno = (int)key;    long offset = PageCacheImpl.pageOffset(pgno);    ByteBuffer buf = ByteBuffer.allocate(PAGE_SIZE);    fileLock.lock();    try &#123;        //通过偏移量获取文件开始读写的位置        fc.position(offset);        fc.read(buf);    &#125; catch(IOException e) &#123;        Panic.panic(e);    &#125;    fileLock.unlock();    return new PageImpl(pgno, buf.array(), this);&#125;private static long pageOffset(int pgno) &#123;    // 页号从 1 开始    return (pgno-1) * PAGE_SIZE;&#125;\n\n（4）驱逐页面releaseForCache(Page pg)，\nprotected void releaseForCache(Page pg) &#123;    if(pg.isDirty()) &#123;        flush(pg);        pg.setDirty(false);    &#125;&#125;private void flush(Page pg) &#123;    int pgno = pg.getPageNumber();    long offset = pageOffset(pgno);    fileLock.lock();    try &#123;        //将数据包装成页面        ByteBuffer buf = ByteBuffer.wrap(pg.getData());        //确定读写位置        fc.position(offset);        //写入缓存        fc.write(buf);        //刷回磁盘        fc.force(false);    &#125; catch(IOException e) &#123;        Panic.panic(e);    &#125; finally &#123;        fileLock.unlock();    &#125;&#125;\n\n（5）使用了一个AtomicInteger，记录当前打开的数据库文件有多少页。\n（6）同一条数据不允许跨页存储。\n（7）数据库的第一页用来做启动检查，具体原理是，每次启动数据库的时候，会生成一段随机字节，存储在 100 ~ 107 字节。在数据库正常关闭时，会将这串字节，拷贝到第一页的 108 ~ 115 字节。这样数据库在每次启动时，就会检查第一页两处的字节是否相同，以此来判断上一次是否正常关闭。如果是异常关闭，就需要执行数据的恢复流程。\n（8）对于普通页的管理与第一页不同。普通页面以一个 2字节无符号数开始，表示这一页的空闲指针，在写前读取空闲指针，并在写后更新空闲指针\n（9）**recoverInsert()和recoverUpdate()**用于在数据库崩溃后重新打开，在下一章中会用到\n\n4.日志文件和恢复策略（1）DM每次对数据文件进行操作时，都会记录一条日志到磁盘；数据库崩溃后，再次启动时可以根据日志内容恢复数据文件，保持其一致性。\n日志的二进制文件，按照如下的格式进行排布：\n[XChecksum][Log1][Log2][Log3]...[LogN][BadTail]\n\n其中 XChecksum 是一个四字节的整数，是对后续所有日志计算的校验和。Log1 ~ LogN 是常规的日志数据，BadTail 是在数据库崩溃时，没有来得及写完的日志数据，这个 BadTail 不一定存在。\n（2）每条日志的格式如下：\n[Size][Checksum][Data]\n\n（3）在打开一个日志文件时，需要首先校验日志文件的 XChecksum，并移除文件尾部可能存在的 BadTail，由于 BadTail 该条日志尚未写入完成，文件的校验和也就不会包含该日志的校验和，去掉 BadTail 即可保证日志文件的一致性。\n（4）向日志文件中写入文件时，先写入文件在更新文件的校验和，更新校验和时使用FileChannel的**force()**方法保证文件会被刷回磁盘\n（5）DM向上提供了两种操作：插入和更新，在进行插入和更新前，必须保证日志写入后，才能够对数据进行操作。\n对于两种数据操作，DM 记录的日志如下：\n\n(Ti, I, A, x)，表示事务 Ti 在 A 位置插入了一条数据 x\n(Ti, U, A, oldx, newx)，表示事务 Ti 将 A 位置的数据，从 oldx 更新成 newx\n\n如果不考虑并发的情况，那么在某一时刻，只可能有一个事务在操作数据库。日志会看起来像下面那样：\n(Ti, x, x), ..., (Ti, x, x), (Tj, x, x), ..., (Tj, x, x), (Tk, x, x), ..., (Tk, x, x)\n\n对于单线程，Ti、Tj 和 Tk 的日志永远不会相交。这种情况下利用日志恢复很简单，假设日志中最后一个事务是 Ti：\n\n对 Ti 之前所有的事务的日志，进行重做（redo）\n接着检查 Ti 的状态（XID 文件），如果 Ti 的状态是已完成（包括 committed 和 aborted），就将 Ti 重做，否则进行撤销（undo）\n\n接着，是如何对事务 T 进行 redo：\n\n正序扫描事务 T 的所有日志\n如果日志是插入操作 (Ti, I, A, x)，就将 x 重新插入 A 位置\n如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 newx\n\nundo 也很好理解：\n\n倒序扫描事务 T 的所有日志\n如果日志是插入操作 (Ti, I, A, x)，就将 A 位置的数据删除\n如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 oldx\n\n对于多线程：\n规定1：正在进行的事务，不会读取其他任何未提交的事务产生的数据。\n规定2：正在进行的事务，不会修改其他任何未提交的事务修改或产生的数据。\n\n5.页面索引与DM实现页面索引，缓存了每一页的空闲空间。用于在上层模块进行插入操作时，能够快速找到一个合适空间的页面，而无需从磁盘或者缓存中检查每一个页面的信息。\n\n6.记录的版本&amp;事务隔离（1）两阶段锁：如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。\n​\t2PL 确实保证了调度序列的可串行化，但是不可避免地导致了事务间的相互阻塞，甚至可能导致死锁。为了提高事务处理的效率，降低阻塞概率，实现了 MVCC。\n（2）MVCC：VM(版本管理)管理所有的数据项，并向上层提供数据记录的概念，上层模块通过VM操作数据记录。VM内部为每个数据记录维护了多个版本，每当上层模块对某个数据记录进行修改时，VM就会为这个记录创建一个新的版本。\n（3）一条数据记录中存储的数据格式如下：\n[XMIN] [XMAX] [DATA]\n\n（4）事务的隔离级别：\n读提交：防止级联回滚；实现读提交，为每个版本维护了两个变量，就是上面提到的 XMIN 和 XMAX：\n\nXMIN：创建该版本的事务编号\nXMAX：删除该版本的事务编号\n\nXMIN 应当在版本创建时填写，而 XMAX 则在版本被删除，或者有新版本出现时填写。XMAX 这个变量，也就解释了为什么 DM 层不提供删除操作，当想删除一个版本时，只需要设置其 XMAX，这样，这个版本对每一个 XMAX 之后的事务都是不可见的，也就等价于删除了。\n在读提交隔离级别下如何判断一条记录是否对当前事务可见：1）获取当前数据记录的xmin和xmax；\n2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n3）判断创建该数据记录的事务是否提交，如果已经提交，进一步进行判断，否则说明当前事务为完成，该数据记录对当前事务不可见；\n4）如果创建该数据记录的事务已经提交，并且xmax不存在，说明该记录违背删除或者修改，该记录对当前事务可见；\n5）如果xmax存在，并且不等于当前事务id，判断xmax事务是否已经提交，若xmax事务还未提交，说明该数据记录对当前版本仍然可见。\n可重复读：解决不可重复读的问题，即一个事务执行期间对同一个数据向多次读取得到不同的结果；\n为实现可重复读，规定当前事务运行时需要忽略：1）再本事务后开始的事务所更新的数据，通过比较事务ID实现；\n2）本事务开始时，还是活跃状态事务的数据，通过再当前事务开始时，记录下当前所有活跃的事务ID；重要：如果xmin也在这个活跃事务的集合中，这个数据也应当对当前事务不可见。\n在可重复读隔离级别下如何判断一条记录是否对当前事务可见：\n1）获取当前数据记录的xmin和xmax；\n2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n3）如果xmin事务已经提交，并且xmin &lt; xid，同时xmin事务已经提交，xmax不存在，说明该数据记录对当前事务可见；\n4）如果事务xmax存在，并且xmax不等于xid，如果事务xmax还未提交，或这事务xmax是再当前事务开始后才开始的，又或是事务xmax还处在获活跃状态，说明该数据记录对当前事务是可见的。\n\n7.死锁检测与VM实现（1）MVCC 的实现，使得 MYDB 在撤销或是回滚事务很简单：只需要将这个事务标记为 aborted 即可。根据前一章提到的可见性，每个事务都只能看到其他 committed 的事务所产生的数据，一个 aborted 事务产生的数据，就不会对其他事务产生任何影响了，也就相当于，这个事务不曾存在过。\n（2）版本跳跃问题：版本跳跃问题，考虑如下的情况，假设 X 最初只有 x0 版本，T1 和 T2 都是可重复读的隔离级别：\nT1 beginT2 beginR1(X) // T1读取x0R2(X) // T2读取x0U1(X) // T1将X更新到x1T1 commitU2(X) // T2将X更新到x2T2 commit\n\n​\t这种情况实际运行起来是没问题的，但是逻辑上不太正确。T1 将 X 从 x0 更新为了 x1，这是没错的。但是 T2 则是将 X 从 x0 更新成了 x2，跳过了 x1 版本。\n​\t读提交是允许版本跳跃的，而可重复读则是不允许版本跳跃的。解决版本跳跃的思路也很简单：如果 Ti 需要修改 X，而 X 已经被 Ti 不可见的事务 Tj 修改了，那么要求 Ti 回滚。\n​\t事务Ti不可见事务Tj有两种情况：\n​\t1）Ti的事务id小于Tj的事务id，即Tj是在Ti开始后才开始的\n​\t2）事务Ti开始时，Tj仍处于活跃状态\n","tags":["MySQL"]},{"title":"随笔","url":"/2025/04/14/%E9%9A%8F%E7%AC%94/","content":"因为去年电脑重做了系统，博客上的文件并没有存下来，所以今天重新搭建了我的博客。回想22年的时候，YH手把手教我和DL搭建博客，那时候好像在看天书一样，什么都不懂，注册github账号时，少打了一个字母，applepiglet变成了applepiget，也行吧。还是像刚学计算机时一样——你好，世界。\n"},{"title":"技术派项目总结","url":"/2025/04/14/%E6%8A%80%E6%9C%AF%E6%B4%BE%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/","content":"技术派项目总结1.Redis中都缓存了哪些数据\n​\t当前登录的用户id，活跃度排行榜，用户操作数据包括点赞以及阅读量，文章的阅读量，pv&#x2F;uv，作者白名单。\n​\t使用Redis缓存这些数据的好处：提升了用户的访问速度，减少了MySQL的访问频率。\n2.缓存中的数据丢失怎么解决\n​\t对缓存中的数据做了持久化，采用了混合持久化的方式，每次写命令都会将命令同步到AOF文件中。\n通过编辑 Redis 的配置文件 redis.conf 来进行设置，或者在运行时通过 Redis 命令行动态调整。\nRDB 持久化通过在配置文件中设置快照（snapshotting）规则来启用。这些规则定义了在多少秒内如果有多少个键被修改，则自动执行一次持久化操作。\nsave 900 1      # 如果至少有1个键被修改，900秒后自动保存一次save 300 10     # 如果至少有10个键被修改，300秒后自动保存一次save 60 10000   # 如果至少有10000个键被修改，60秒后自动保存一次\n\nAOF 持久化是通过在配置文件中设置 appendonly 参数为 yes 来启用的：\nappendonly yes\n\n此外，还可以配置 AOF 文件的写入频率，这是通过 appendfsync 设置的：\nappendfsync always    # 每次写入数据都同步，保证数据不丢失，但性能较低appendfsync everysec  # 每秒同步一次，折衷方案appendfsync no        # 由操作系统决定何时同步，性能最好，但数据安全性最低\n\n\n\n3.排行榜如何实现\n​\t对用户的操作进行监听，触发更新事件，细节见下面两个问题。\n4.增加或减少活跃度时如何做幂等判断\n​\t一个简单的方案就是将用户的每个加分项，都直接记录下来，在执行具体加分时，基于此来做幂等判定。基于上面这个思路，很容易想到的一个方案就是，每个用户维护一个活跃更新操作历史记录表，我们先尽量设计得轻量级一点。直接将用户的历史日志，保存在redis的hash数据结构中，每天对应一个记录。\n​\t在增加&#x2F;减少活跃度时，首先查询缓存判断是否已经进行过这种操作，如果没有就继续执行，否则直接返回。\nkey: activity_rank_&#123;user_id&#125;_&#123;年月日&#125;\nfield: 活跃度更新key\nvalue: 添加的活跃度\n\n​\t\n5.如何更新排行榜\n​\t首先为了保证活跃度更新时的原子性，使用Redis中zset提供的incr方法对数据进行增减。\n​\t对于用户的操作通过事件监听出发活跃度的更新，Listener代码如下：\n@EventListener(classes = NotifyMsgEvent.class)    @Async    public void notifyMsgListener(NotifyMsgEvent msgEvent) &#123;        switch (msgEvent.getNotifyType()) &#123;            case COMMENT:            case REPLY:                CommentDO comment = (CommentDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setRate(true).setArticleId(comment.getArticleId()));                break;            case COLLECT:                UserFootDO foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setCollect(true).setArticleId(foot.getDocumentId()));                break;            case CANCEL_COLLECT:                foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setCollect(false).setArticleId(foot.getDocumentId()));                break;            case PRAISE:                foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setPraise(true).setArticleId(foot.getDocumentId()));                break;            case CANCEL_PRAISE:                foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setPraise(false).setArticleId(foot.getDocumentId()));                break;            case FOLLOW:                UserRelationDO relation = (UserRelationDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setFollow(true).setFollowedUserId(relation.getUserId()));                break;            case CANCEL_FOLLOW:                relation = (UserRelationDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setFollow(false).setFollowedUserId(relation.getUserId()));                break;            default:        &#125;    &#125;\n\n​\t此外，用户发布文章也会增加活跃度，额外设置一个Listener，监听文章发布事件，当文章成功发布（状态为Online），出发更新操作，代码如下：\n@Async    @EventListener(ArticleMsgEvent.class)    public void publishArticleListener(ArticleMsgEvent&lt;ArticleDO&gt; event) &#123;        ArticleEventEnum type = event.getType();        if (type == ArticleEventEnum.ONLINE) &#123;            userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setPublishArticle(true).setArticleId(event.getContent().getId()));        &#125;    &#125;\n\n具体实现细节：\n​\t当监听到用户操作时，Listener首先判断操作类型，然后通过接口userActivityRankService中的addActivityScore方法对用户的活跃读进行增减。\n​\t在真正对分数进行修改前，通过userfoot表（用户足迹表，记录了用户对某篇文章的一系列操作，包括点赞、收藏等）查询用户之前是否进行过这种操作，如果存在记录直接返回，否则进行活跃度的更新。\n6.项目中的JWT时如何实现的\n​\t项目中的JWT token用的长 token，配置了 30 天的有效期，这样用户体验更流畅，不用频繁重新登录。 用户登录成功后，后端将生成的jwt返回给前端，然后前端将其保存在本地缓存；\n​\t之后前端与后端的交互时，都将JWT token放在请求头中，比如可以将其放在Http身份认证的请求头Authorization中，也可以通过自定义的请求头来传递；后端接收到用户的请求，从请求头中获取JWT，然后进行校验，通过之后，才响应相关的接口；否则表示未登录 。\n7.JWT不支持续期，如果用户正在使用中JWT失效了如何解决\n​\t每次用户请求时，如果离过期不远了（比如只剩 5 分钟），就自动生成一个新的 token；返回给前端 → 前端替换旧 token； \n​\t或者用 Redis 设置一个有效期 + TTL（Time To Live，生存时间）滑动延长。用户登录的时候，生成一个 token，将 token 存入 Redis，设置有效期，比如说三十分钟。 用户发起请求时，在拦截器中获取 token，验证其是否在 Redis 中，是否过期。如果有效内，自动延长 30 分钟。 每次请求都延期一下，让 TTL 滑动前进，用户只要活跃就不会掉线。一旦用户长时间不操作，TTL 自动过期，登录状态失效。\n8.从ES中的hits获得了文章id，再去查数据库，性能会提升吗？为什么要用ES而不直接去MySQL里面查\n​\t对于全文检索场景，ES 毫秒级响应（倒排索引），更适合模糊搜索（如文章标题、内容），使用MySQL的LIKE模糊查询速度慢，如果又前缀模糊的情况还会导致全表搜索。复杂条件组合查询（如标签+时间+关键词），ES单次查询效率远高于MySQL多表关联 ，ES专注复杂搜索，MySQL承担事务型操作，符合计算存储分离趋势。可先通过ES筛选符合条件的文章ID，再用MySQL补全未索引字段。\n9.如果这个项目在高并发的场景下，比如很多用户同时点赞评论，应该如何优化？\nrabbitmq 削峰；\n或者通过令牌桶或漏桶算法限制突发流量，如 RateLimiter；另外，将短时间内的多次点赞合并为一次操作，短时间内同一文章的多条点赞合并为一次INCR操作。\n10.采用自旋锁策略优化缓存结构，针对热key的并发访问进行同步，防止其失效时导致的缓存击穿\n​\t当某个Key失效时，第一个请求发现缓存未命中，尝试通过CAS操作获取锁，其他并发请求在短时间内（如1ms）自旋轮询锁状态，避免线程阻塞和上下文切换开销。获得锁的线程从数据库加载数据并写入缓存，完成后释放锁，其他请求直接从缓存读取。 在业务代码中埋点，针对特定场景（如热门文章、秒杀商品）预标记为热Key。\n11.用户如何进行登录的\n​\t1) 使用用户名和密码进行登录，用户输入用户名和密码，然后到数据库进行校验，如果查询到了记录，返回session放入响应体中，否则返回登录异常信息。用户注册时，对密码进行加盐并进行md5编码存储到数据库中。\n​\t2）微信公众号登录，\n","tags":["Pai-Coding"]},{"title":"动态规划","url":"/2025/04/15/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","content":"​\t最近在做动态规划题的时候时常感到困惑，为什么这个题的边界要初始化，为什么这个题的边界不用初始化，为什么这个两个题明明代码都是一样的初始化的条件却不同，写算法题的时候遇到这种情况真的很痛苦，很想手动模拟，一个一个的算出来对应的值，看一下究竟为什么。但是受限于时间，我先记录对这种情况进行记录，之后慢慢深究。\n首先是LeetCode上的62. 不同路径，这个题我第一遍的时候写了两种做法，两种做法的整体思路都是一样的，但是对应的边界条件不同。代码如下：\n//写法1：public int uniquePaths(int m, int n) &#123;    int[][] f = new int[m][n4];    for(int i = 0; i &lt; m; i ++)&#123;        f[i][0] = 1;    &#125;    for(int j = 0; j &lt; n; j ++)&#123;        f[0][j] = 1;    &#125;    for(int i = 1; i &lt; m; i ++)&#123;        for(int j = 1; j &lt; n; j ++)&#123;            f[i][j] = f[i - 1][j] + f[i][j - 1];        &#125;    &#125;    return f[m - 1][n - 1];&#125;\n\n写法1很好理解，只需要初始化最上边和最右边的所有路径数为1就好，剩下的就是状态转移了。\n//写法2：public int uniquePaths(int m, int n) &#123;    int[][] f = new int[m + 1][n + 1];   \tf[0][1] = 1;    for(int i = 0; i &lt; m; i ++)&#123;        for(int j = 0; j &lt; n; j ++)&#123;            f[i + 1][j + 1] = f[i + 1][j] + f[i][j + 1];        &#125;    &#125;    return f[m][n];&#125;\n\n写法二考虑了边界情况，将动态规划数组初始化为0 -&gt; m和0 -&gt; n，这样i和j就可以从0开始遍历。但是这样带来一个问题，即原二维数组中的(0，0)对应动态规划数组中的(1，1)，因此就不能像写法一中那样进行初始化了，写法二中将f(0，1)初始化为1（也可以将f(1，0）初始化为1，只能初始化一个），f(0，1)对应的是二维数组中(-1，0)，也就是方格外的区域，这样初始化后，在第一次循环的时候会将f(1，1)初始化成1，而f(1，1)对应的是方格中的(0，0)。\n","tags":["动态规划"]}]