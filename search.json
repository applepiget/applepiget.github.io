[{"title":"MYDB项目总结","url":"/2025/04/14/MYDB%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/","content":"MYDB1.为什么使用NIO，有哪些好处\n2.日志是怎么做的\n3.如何处理可见性\n​\t1）根据数据库不同的隔离级别来保证不同的可见性\n​\t2）读未提交：这时不对事务的可见性做任何处理，可能会导致脏读、不可重复读、幻读；\n​\t3）读提交：引入MVCC\n​\t\t在读提交隔离级别下如何判断一条记录是否对当前事务可见：​\t\t1）获取当前数据记录的xmin和xmax；\n​\t\t2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n​\t\t3）判断创建该数据记录的事务是否提交，如果已经提交，进一步进行判断，否则说明当前事务为完成，该数据记录对当前事务不可见；\n​\t\t4）如果创建该数据记录的事务已经提交，并且xmax不存在，说明该记录违背删除或者修改，该记录对当前事务可见；\n​\t\t5）如果xmax存在，并且不等于当前事务id，判断xmax事务是否已经提交，若xmax事务还未提交，说明该数据记录对当前版本仍然可见。\n​\t4）读未提交：同样引入MVCC\n​\t\t在可重复读隔离级别下如何判断一条记录是否对当前事务可见：\n​\t\t1）获取当前数据记录的xmin和xmax；\n​\t\t2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n​\t\t3）如果xmin事务已经提交，并且xmin &lt; xid，同时xmin事务已经提交，xmax不存在，说明该数据记录对当前事务可见；\n​\t\t4）如果事务xmax存在，并且xmax不等于xid，如果事务xmax还未提交，或这事务xmax是再当前事务开始后才开始的，又或是事务xmax还处在获活跃状态，说明该数据记录对当前事务是可见的。\n​\t5）串行化：使用两阶段锁，如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。\n4.ACID如何实现\n​\t1）原子性：项目中的事务分为活跃、提交和回滚三个状态，主要是通过对事务状态的保存来确保事务的原子性；\n​\t2）持久性：通过记录日志来保证数据库的持久性，以及事务提交时强制刷盘，保证数据已经写入磁盘中，一次来保证数据库的持久性；\n​\t3）一致性：通过实现其他三种性质来保证一致性；\n​\t4）隔离性：通过数据库中实现的MVCC来保证数据之间的隔离性。\n5.死锁如何处理\n​\t1）当一个事务请求获取某个资源时，首先会检查该资源是否已被其他事务持有。如果没有被持有，资源将直接分配给请求的事务。如果资源已被占用，事务将进入等待状态，并存储在相应的等待队列中。\n​\t2）在某些情况下，事务可能会由于等待时间过长而被回滚。通过后台线程定期检查每个事务的等待时间，并在超时时执行回滚操作。 超时检测与回滚机制的基本思想是：\n\n每个事务在获取资源时，如果资源被其他事务占用，则需要等待。\n为了避免长时间等待导致系统资源被锁住，我们为每个等待的事务设置一个超时时间（30S）。\n当检测到事务等待超时后，系统将回滚这个事务，并释放它占用的所有资源，从而避免死锁或资源饥饿。\n\n启动一个后台线程，定期检查每个事务的等待时间。如果超时，则执行回滚操作。\n6.存储和空间回收如何处理\n​\tMVCC的版本清理：若当前版本的事务ID已提交且无活跃事务引用，则可以清除该版本\n7.介绍下项目中的B+树\n8.SQL语句解析\n​\t1）将SQL语句解析为多个token，其中引号中的内容被当作一个token\n​\t2）根据SQL语句的第一个字段来执行不同的操作\n\n1.TM (Transaction Manager) 事务管理（1）XID 事务ID，每个事务对应一个ID\n（2）事务状态，active&#x2F;活跃，commited&#x2F;提交，aborted&#x2F;回滚\n（3）文件读写采用NIO，NIO与BIO的对比如下\n​\t\t阻塞与非阻塞\n\nBIO：在进行 I&#x2F;O 操作时，线程会被阻塞。比如在读取数据时，线程会一直等待直到数据完全读取完毕；在写入数据时，会一直等待直到数据全部写入。这种阻塞特性会导致线程在等待过程中无法进行其他工作，造成资源浪费。举例来说，一个服务器使用 BIO 处理多个客户端连接时，每个连接都需要一个独立的线程来处理，若某个客户端连接数据传输缓慢，会使对应线程长时间阻塞，影响系统整体性能。\nNIO：采用非阻塞模式，线程在进行 I&#x2F;O 操作时不会被阻塞，可以去执行其他任务。线程可以询问是否有数据准备好，若没有则可以继续执行其他代码，之后再回来检查。例如，服务器使用 NIO 时，一个线程可以处理多个客户端连接，当某个连接没有数据可读时，线程不会等待，而是去处理其他连接，提高了线程的利用率。\n\n​\t\t多路复用机制\n\nBIO：缺乏有效的多路复用机制，若要处理多个客户端连接，通常需要为每个连接创建一个独立的线程。线程的创建和销毁会带来较大的开销，并且过多的线程会导致系统资源竞争激烈，增加上下文切换的开销，降低系统性能。\nNIO：引入了选择器（Selector），它是 NIO 实现多路复用的核心。一个选择器可以同时监听多个通道（Channel）的事件，如读、写、连接等。线程可以通过选择器来轮询哪些通道有事件发生，然后对这些通道进行相应的处理。这样，一个线程就可以处理多个客户端连接，减少了线程的使用数量，降低了系统开销。\n\n​\t\t缓冲区与通道\n\nBIO：使用流（Stream）的方式进行数据传输，数据的读写是单向的，输入流只能读，输出流只能写。而且流的操作是基于字节或字符的，每次只能处理一个或多个字节 &#x2F; 字符，效率较低。\nNIO：采用缓冲区（Buffer）和通道（Channel）的方式进行数据传输。通道是双向的，可以同时进行读写操作，提高了数据传输的灵活性。缓冲区是一个连续的内存块，数据可以批量地从通道读取到缓冲区，或者从缓冲区写入到通道，减少了数据的复制次数，提高了数据传输的效率。\n\n（4）**begin()**方法，开启一个事务并将其设置为活跃状态，同时事务id计数器自增\n（5）updateXID()方法，更新事务状态，后面的commit() ,**abort()**方法就可以直接借助 updateXID() 方法实现\n（6）检查事务状态的三个方法 isActive(), isCommited(), isAborted()\n（7）静态方法create()，创建一个XID文件\n（8）静态方法open()，从一个已有的XID文件来创建TM\n\n2.DM (Data Manager) 数据管理（1）DM直接管理数据库DB文件和日志文件，具体职责如下：1）分页管理DB文件，并进行缓存；2）管理日志文件，保证数据库在发生错误时根据日志进行恢复；3）抽象DB文件为DataItem，提供给尚存使用，并提供缓存\n（2）引用计数法设计缓存，当计数为0时，直接从缓存中删除这个资源；同时，缓存满了之后应该直接报错。定义了一个抽象类：\nAbstractCache&lt;T&gt;/** * 当资源不在缓存时的获取行为 */protected abstract T getForCache(long key) throws Exception;/** * 当资源被驱逐时的写回行为 */protected abstract void releaseForCache(T obj);\n\n同时，为应对多线程并发场景，额外记录了哪些资源正在被读取，构造了以下三个数据结构：\nprivate HashMap&lt;Long, T&gt; cache;                     // 实际缓存的数据private HashMap&lt;Long, Integer&gt; references;          // 资源的引用个数private HashMap&lt;Long, Boolean&gt; getting;             // 正在被获取的资源\n\n因此在读取缓存时，首先进入死循环，一直尝试从缓存中获取数据，同时检查是否有其他线程正在使用这个数据；\n如果数据在缓存中，直接返回，同时引用计数+1；\n如果不在缓存中，首先在getting中对数据进行标记，表示其正在被使用，在用**getForCache(long key)**获取缓存。\n\n3.数据页的缓存与管理（1）DM向下将文件系统抽象成页面，每次对文件的读写都是以页面为单位的，同时缓存也是以页面为单位进行的，页面缓存存储在内存中。\n（2）数据页大小为8K，借用上一节已经实现的引用计数缓存框架进行缓存，数据页的数据结构如下：\npublic class PageImpl implements Page&#123;\tprivate int pageNumber;\t//页号    private byte[] data;\t//数据内容    private boolean ditry; \t//是否为脏页    private Lock lock;        private PageCache pc;&#125;\n\n（3）获取缓存getForCache(long key)，传入的参数为页号\nprotected Page getForCache(long key) throws Exception &#123;    int pgno = (int)key;    long offset = PageCacheImpl.pageOffset(pgno);    ByteBuffer buf = ByteBuffer.allocate(PAGE_SIZE);    fileLock.lock();    try &#123;        //通过偏移量获取文件开始读写的位置        fc.position(offset);        fc.read(buf);    &#125; catch(IOException e) &#123;        Panic.panic(e);    &#125;    fileLock.unlock();    return new PageImpl(pgno, buf.array(), this);&#125;private static long pageOffset(int pgno) &#123;    // 页号从 1 开始    return (pgno-1) * PAGE_SIZE;&#125;\n\n（4）驱逐页面releaseForCache(Page pg)，\nprotected void releaseForCache(Page pg) &#123;    if(pg.isDirty()) &#123;        flush(pg);        pg.setDirty(false);    &#125;&#125;private void flush(Page pg) &#123;    int pgno = pg.getPageNumber();    long offset = pageOffset(pgno);    fileLock.lock();    try &#123;        //将数据包装成页面        ByteBuffer buf = ByteBuffer.wrap(pg.getData());        //确定读写位置        fc.position(offset);        //写入缓存        fc.write(buf);        //刷回磁盘        fc.force(false);    &#125; catch(IOException e) &#123;        Panic.panic(e);    &#125; finally &#123;        fileLock.unlock();    &#125;&#125;\n\n（5）使用了一个AtomicInteger，记录当前打开的数据库文件有多少页。\n（6）同一条数据不允许跨页存储。\n（7）数据库的第一页用来做启动检查，具体原理是，每次启动数据库的时候，会生成一段随机字节，存储在 100 ~ 107 字节。在数据库正常关闭时，会将这串字节，拷贝到第一页的 108 ~ 115 字节。这样数据库在每次启动时，就会检查第一页两处的字节是否相同，以此来判断上一次是否正常关闭。如果是异常关闭，就需要执行数据的恢复流程。\n（8）对于普通页的管理与第一页不同。普通页面以一个 2字节无符号数开始，表示这一页的空闲指针，在写前读取空闲指针，并在写后更新空闲指针\n（9）**recoverInsert()和recoverUpdate()**用于在数据库崩溃后重新打开，在下一章中会用到\n\n4.日志文件和恢复策略（1）DM每次对数据文件进行操作时，都会记录一条日志到磁盘；数据库崩溃后，再次启动时可以根据日志内容恢复数据文件，保持其一致性。\n日志的二进制文件，按照如下的格式进行排布：\n[XChecksum][Log1][Log2][Log3]...[LogN][BadTail]\n\n其中 XChecksum 是一个四字节的整数，是对后续所有日志计算的校验和。Log1 ~ LogN 是常规的日志数据，BadTail 是在数据库崩溃时，没有来得及写完的日志数据，这个 BadTail 不一定存在。\n（2）每条日志的格式如下：\n[Size][Checksum][Data]\n\n（3）在打开一个日志文件时，需要首先校验日志文件的 XChecksum，并移除文件尾部可能存在的 BadTail，由于 BadTail 该条日志尚未写入完成，文件的校验和也就不会包含该日志的校验和，去掉 BadTail 即可保证日志文件的一致性。\n（4）向日志文件中写入文件时，先写入文件在更新文件的校验和，更新校验和时使用FileChannel的**force()**方法保证文件会被刷回磁盘\n（5）DM向上提供了两种操作：插入和更新，在进行插入和更新前，必须保证日志写入后，才能够对数据进行操作。\n对于两种数据操作，DM 记录的日志如下：\n\n(Ti, I, A, x)，表示事务 Ti 在 A 位置插入了一条数据 x\n(Ti, U, A, oldx, newx)，表示事务 Ti 将 A 位置的数据，从 oldx 更新成 newx\n\n如果不考虑并发的情况，那么在某一时刻，只可能有一个事务在操作数据库。日志会看起来像下面那样：\n(Ti, x, x), ..., (Ti, x, x), (Tj, x, x), ..., (Tj, x, x), (Tk, x, x), ..., (Tk, x, x)\n\n对于单线程，Ti、Tj 和 Tk 的日志永远不会相交。这种情况下利用日志恢复很简单，假设日志中最后一个事务是 Ti：\n\n对 Ti 之前所有的事务的日志，进行重做（redo）\n接着检查 Ti 的状态（XID 文件），如果 Ti 的状态是已完成（包括 committed 和 aborted），就将 Ti 重做，否则进行撤销（undo）\n\n接着，是如何对事务 T 进行 redo：\n\n正序扫描事务 T 的所有日志\n如果日志是插入操作 (Ti, I, A, x)，就将 x 重新插入 A 位置\n如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 newx\n\nundo 也很好理解：\n\n倒序扫描事务 T 的所有日志\n如果日志是插入操作 (Ti, I, A, x)，就将 A 位置的数据删除\n如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 oldx\n\n对于多线程：\n规定1：正在进行的事务，不会读取其他任何未提交的事务产生的数据。\n规定2：正在进行的事务，不会修改其他任何未提交的事务修改或产生的数据。\n\n5.页面索引与DM实现页面索引，缓存了每一页的空闲空间。用于在上层模块进行插入操作时，能够快速找到一个合适空间的页面，而无需从磁盘或者缓存中检查每一个页面的信息。\n\n6.记录的版本&amp;事务隔离（1）两阶段锁：如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。\n​\t2PL 确实保证了调度序列的可串行化，但是不可避免地导致了事务间的相互阻塞，甚至可能导致死锁。为了提高事务处理的效率，降低阻塞概率，实现了 MVCC。\n（2）MVCC：VM(版本管理)管理所有的数据项，并向上层提供数据记录的概念，上层模块通过VM操作数据记录。VM内部为每个数据记录维护了多个版本，每当上层模块对某个数据记录进行修改时，VM就会为这个记录创建一个新的版本。\n（3）一条数据记录中存储的数据格式如下：\n[XMIN] [XMAX] [DATA]\n\n（4）事务的隔离级别：\n读提交：防止级联回滚；实现读提交，为每个版本维护了两个变量，就是上面提到的 XMIN 和 XMAX：\n\nXMIN：创建该版本的事务编号\nXMAX：删除该版本的事务编号\n\nXMIN 应当在版本创建时填写，而 XMAX 则在版本被删除，或者有新版本出现时填写。XMAX 这个变量，也就解释了为什么 DM 层不提供删除操作，当想删除一个版本时，只需要设置其 XMAX，这样，这个版本对每一个 XMAX 之后的事务都是不可见的，也就等价于删除了。\n在读提交隔离级别下如何判断一条记录是否对当前事务可见：1）获取当前数据记录的xmin和xmax；\n2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n3）判断创建该数据记录的事务是否提交，如果已经提交，进一步进行判断，否则说明当前事务为完成，该数据记录对当前事务不可见；\n4）如果创建该数据记录的事务已经提交，并且xmax不存在，说明该记录违背删除或者修改，该记录对当前事务可见；\n5）如果xmax存在，并且不等于当前事务id，判断xmax事务是否已经提交，若xmax事务还未提交，说明该数据记录对当前版本仍然可见。\n可重复读：解决不可重复读的问题，即一个事务执行期间对同一个数据向多次读取得到不同的结果；\n为实现可重复读，规定当前事务运行时需要忽略：1）再本事务后开始的事务所更新的数据，通过比较事务ID实现；\n2）本事务开始时，还是活跃状态事务的数据，通过再当前事务开始时，记录下当前所有活跃的事务ID；重要：如果xmin也在这个活跃事务的集合中，这个数据也应当对当前事务不可见。\n在可重复读隔离级别下如何判断一条记录是否对当前事务可见：\n1）获取当前数据记录的xmin和xmax；\n2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n3）如果xmin事务已经提交，并且xmin &lt; xid，同时xmin事务已经提交，xmax不存在，说明该数据记录对当前事务可见；\n4）如果事务xmax存在，并且xmax不等于xid，如果事务xmax还未提交，或这事务xmax是再当前事务开始后才开始的，又或是事务xmax还处在获活跃状态，说明该数据记录对当前事务是可见的。\n\n7.死锁检测与VM实现（1）MVCC 的实现，使得 MYDB 在撤销或是回滚事务很简单：只需要将这个事务标记为 aborted 即可。根据前一章提到的可见性，每个事务都只能看到其他 committed 的事务所产生的数据，一个 aborted 事务产生的数据，就不会对其他事务产生任何影响了，也就相当于，这个事务不曾存在过。\n（2）版本跳跃问题：版本跳跃问题，考虑如下的情况，假设 X 最初只有 x0 版本，T1 和 T2 都是可重复读的隔离级别：\nT1 beginT2 beginR1(X) // T1读取x0R2(X) // T2读取x0U1(X) // T1将X更新到x1T1 commitU2(X) // T2将X更新到x2T2 commit\n\n​\t这种情况实际运行起来是没问题的，但是逻辑上不太正确。T1 将 X 从 x0 更新为了 x1，这是没错的。但是 T2 则是将 X 从 x0 更新成了 x2，跳过了 x1 版本。\n​\t读提交是允许版本跳跃的，而可重复读则是不允许版本跳跃的。解决版本跳跃的思路也很简单：如果 Ti 需要修改 X，而 X 已经被 Ti 不可见的事务 Tj 修改了，那么要求 Ti 回滚。\n​\t事务Ti不可见事务Tj有两种情况：\n​\t1）Ti的事务id小于Tj的事务id，即Tj是在Ti开始后才开始的\n​\t2）事务Ti开始时，Tj仍处于活跃状态\n","tags":["MySQL"]},{"title":"随笔","url":"/2025/04/14/%E9%9A%8F%E7%AC%94/","content":"因为去年电脑重做了系统，博客上的文件并没有存下来，所以今天重新搭建了我的博客。回想22年的时候，YH手把手教我和DL搭建博客，那时候好像在看天书一样，什么都不懂，注册github账号时，少打了一个字母，applepiglet变成了applepiget，也行吧。还是像刚学计算机时一样——你好，世界。\n"},{"title":"技术派项目总结","url":"/2025/04/14/%E6%8A%80%E6%9C%AF%E6%B4%BE%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/","content":"技术派项目总结1.Redis中都缓存了哪些数据\n​\t当前登录的用户id，活跃度排行榜，用户操作数据包括点赞以及阅读量，文章的阅读量，pv&#x2F;uv，作者白名单。\n​\t使用Redis缓存这些数据的好处：提升了用户的访问速度，减少了MySQL的访问频率。\n2.缓存中的数据丢失怎么解决\n​\t对缓存中的数据做了持久化，采用了混合持久化的方式，每次写命令都会将命令同步到AOF文件中。\n通过编辑 Redis 的配置文件 redis.conf 来进行设置，或者在运行时通过 Redis 命令行动态调整。\nRDB 持久化通过在配置文件中设置快照（snapshotting）规则来启用。这些规则定义了在多少秒内如果有多少个键被修改，则自动执行一次持久化操作。\nsave 900 1      # 如果至少有1个键被修改，900秒后自动保存一次save 300 10     # 如果至少有10个键被修改，300秒后自动保存一次save 60 10000   # 如果至少有10000个键被修改，60秒后自动保存一次\n\nAOF 持久化是通过在配置文件中设置 appendonly 参数为 yes 来启用的：\nappendonly yes\n\n此外，还可以配置 AOF 文件的写入频率，这是通过 appendfsync 设置的：\nappendfsync always    # 每次写入数据都同步，保证数据不丢失，但性能较低appendfsync everysec  # 每秒同步一次，折衷方案appendfsync no        # 由操作系统决定何时同步，性能最好，但数据安全性最低\n\n\n\n3.排行榜如何实现\n​\t对用户的操作进行监听，触发更新事件，细节见下面两个问题。\n4.增加或减少活跃度时如何做幂等判断\n​\t一个简单的方案就是将用户的每个加分项，都直接记录下来，在执行具体加分时，基于此来做幂等判定。基于上面这个思路，很容易想到的一个方案就是，每个用户维护一个活跃更新操作历史记录表，我们先尽量设计得轻量级一点。直接将用户的历史日志，保存在redis的hash数据结构中，每天对应一个记录。\n​\t在增加&#x2F;减少活跃度时，首先查询缓存判断是否已经进行过这种操作，如果没有就继续执行，否则直接返回。\nkey: activity_rank_&#123;user_id&#125;_&#123;年月日&#125;\nfield: 活跃度更新key\nvalue: 添加的活跃度\n\n​\t\n5.如何更新排行榜\n​\t首先为了保证活跃度更新时的原子性，使用Redis中zset提供的incr方法对数据进行增减。\n​\t对于用户的操作通过事件监听出发活跃度的更新，Listener代码如下：\n@EventListener(classes = NotifyMsgEvent.class)    @Async    public void notifyMsgListener(NotifyMsgEvent msgEvent) &#123;        switch (msgEvent.getNotifyType()) &#123;            case COMMENT:            case REPLY:                CommentDO comment = (CommentDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setRate(true).setArticleId(comment.getArticleId()));                break;            case COLLECT:                UserFootDO foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setCollect(true).setArticleId(foot.getDocumentId()));                break;            case CANCEL_COLLECT:                foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setCollect(false).setArticleId(foot.getDocumentId()));                break;            case PRAISE:                foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setPraise(true).setArticleId(foot.getDocumentId()));                break;            case CANCEL_PRAISE:                foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setPraise(false).setArticleId(foot.getDocumentId()));                break;            case FOLLOW:                UserRelationDO relation = (UserRelationDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setFollow(true).setFollowedUserId(relation.getUserId()));                break;            case CANCEL_FOLLOW:                relation = (UserRelationDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setFollow(false).setFollowedUserId(relation.getUserId()));                break;            default:        &#125;    &#125;\n\n​\t此外，用户发布文章也会增加活跃度，额外设置一个Listener，监听文章发布事件，当文章成功发布（状态为Online），出发更新操作，代码如下：\n@Async    @EventListener(ArticleMsgEvent.class)    public void publishArticleListener(ArticleMsgEvent&lt;ArticleDO&gt; event) &#123;        ArticleEventEnum type = event.getType();        if (type == ArticleEventEnum.ONLINE) &#123;            userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setPublishArticle(true).setArticleId(event.getContent().getId()));        &#125;    &#125;\n\n具体实现细节：\n​\t当监听到用户操作时，Listener首先判断操作类型，然后通过接口userActivityRankService中的addActivityScore方法对用户的活跃读进行增减。\n​\t在真正对分数进行修改前，通过userfoot表（用户足迹表，记录了用户对某篇文章的一系列操作，包括点赞、收藏等）查询用户之前是否进行过这种操作，如果存在记录直接返回，否则进行活跃度的更新。\n6.项目中的JWT时如何实现的\n​\t项目中的JWT token用的长 token，配置了 30 天的有效期，这样用户体验更流畅，不用频繁重新登录。 用户登录成功后，后端将生成的jwt返回给前端，然后前端将其保存在本地缓存；\n​\t之后前端与后端的交互时，都将JWT token放在请求头中，比如可以将其放在Http身份认证的请求头Authorization中，也可以通过自定义的请求头来传递；后端接收到用户的请求，从请求头中获取JWT，然后进行校验，通过之后，才响应相关的接口；否则表示未登录 。\n7.JWT不支持续期，如果用户正在使用中JWT失效了如何解决\n​\t每次用户请求时，如果离过期不远了（比如只剩 5 分钟），就自动生成一个新的 token；返回给前端 → 前端替换旧 token； \n​\t或者用 Redis 设置一个有效期 + TTL（Time To Live，生存时间）滑动延长。用户登录的时候，生成一个 token，将 token 存入 Redis，设置有效期，比如说三十分钟。 用户发起请求时，在拦截器中获取 token，验证其是否在 Redis 中，是否过期。如果有效内，自动延长 30 分钟。 每次请求都延期一下，让 TTL 滑动前进，用户只要活跃就不会掉线。一旦用户长时间不操作，TTL 自动过期，登录状态失效。\n8.从ES中的hits获得了文章id，再去查数据库，性能会提升吗？为什么要用ES而不直接去MySQL里面查\n​\t对于全文检索场景，ES 毫秒级响应（倒排索引），更适合模糊搜索（如文章标题、内容），使用MySQL的LIKE模糊查询速度慢，如果又前缀模糊的情况还会导致全表搜索。复杂条件组合查询（如标签+时间+关键词），ES单次查询效率远高于MySQL多表关联 ，ES专注复杂搜索，MySQL承担事务型操作，符合计算存储分离趋势。可先通过ES筛选符合条件的文章ID，再用MySQL补全未索引字段。\n9.如果这个项目在高并发的场景下，比如很多用户同时点赞评论，应该如何优化？\nRabbitMQ 削峰；\n或者通过令牌桶或漏桶算法限制突发流量，如 RateLimiter；另外，将短时间内的多次点赞合并为一次操作，短时间内同一文章的多条点赞合并为一次INCR操作。\n10.采用自旋锁策略优化缓存结构，针对热key的并发访问进行同步，防止其失效时导致的缓存击穿\n​\t当某个Key失效时，第一个请求发现缓存未命中，尝试通过CAS操作获取锁，其他并发请求在短时间内（如1ms）自旋轮询锁状态，避免线程阻塞和上下文切换开销。获得锁的线程从数据库加载数据并写入缓存，完成后释放锁，其他请求直接从缓存读取。 在业务代码中埋点，针对特定场景（如热门文章、秒杀商品）预标记为热Key。\n11.用户如何进行登录的\n​\t1) 使用用户名和密码进行登录，用户输入用户名和密码，然后到数据库进行校验，如果查询到了记录，返回session放入响应体中，否则返回登录异常信息。用户注册时，对密码进行加盐并进行md5编码存储到数据库中。\n​\t2）微信公众号登录，\n12.项目难点\n​\t1）自定义的雪花算法：时间戳从亳秒改为秒；生成id前五位：年+天；\nworkCenterld:dataCenterld&#x3D;3:7；当时钟回拨时，等待时间追上，而不是直接抛异常。\n​\t**雪花算法缺点：**强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。\n​\t在项目中，并不是每次需要id时，再去调用雪花算法来实时生成;更常见的做法时提前生成好，放在队列中，有需要就从中获取;当队列数据少于某个值时，自动填充id上面这个思路，可以说是将雪花算法 +号段的思想结合起来，应用于业务主键id的生成，最大限度的提高id生成器的可用性以及相应效率。\n​\t针对如果是今天发的文章，但是队列中保存的仍然是昨天的id，如何解决？\n​\t如果出现了跨天的情况，会将队列中的id清空\n2）分布式锁：\t使用Redis 的 setIfAbsent(key,value,time)手动释放锁，但遇到了锁不能及时释放的问题、误释放别人的锁，以及过期时间的设置是否合理等问题。\n​\t导致错误释放别人的锁的原因：\n​\t1）未记录锁的持有者：释放锁时未校验当前锁是否属于自己，直接删除 key。\n​\t2）锁过期与业务处理不同步：业务处理时间超过锁的过期时间，导致锁被提前释放，其他客户端获取到新锁，原客户端仍误认为自己持有锁。\n​\t正确释放方法：\n​\t1）获取锁是携带唯一标识，标识着锁的持有者；\n​\t2）释放锁是，使用Lua脚本原子性的校验并删除锁。\n​\t最后引入 Redission 的看门狗算法进行解决，这样就可以一劳永逸了，不过手动尝试的方式的确也让我对看门狗算法有了一个更深入更直接的了解，它的内部实现也是按照我之前手动的逻辑实现的，起一个定时任务，每 10 秒检查一下锁是否释放，如果没有释放就延长至 30 秒。\n13.项目优化\n14.本地缓存\n​\t引入Caffeine，对页面的侧边栏进行缓存，侧边栏数据变动较少，大多时候都不会改变，能够有效减少访问数据库的次数。\n​\t在**@Cacheable中添加参数cacheManager**指定要使用哪个 CacheManager 来管理缓存操作。要是不指定 cacheManager 属性，Spring 会采用默认的 cacheManager。\n15.Lua脚本为什么能保证原子性\n​\t1）Redis 采用单线程的事件循环机制来处理客户端的请求。这意味着在同一时间，Redis 只能执行一个命令或者一个 Lua 脚本。当一个 Lua 脚本被发送到 Redis 服务器执行时，Redis 会暂停处理其他客户端的请求，直到该 Lua 脚本执行完毕。\n​\t2）Redis 内置了 Lua 解释器，当接收到一个 Lua 脚本时，Redis 会将其加载到内存中并执行。整个脚本的执行过程是连续的，不会被其他命令打断。\n​\t3）在 Redis 中，Lua 脚本可以看作是一种特殊的事务。它将多个 Redis 命令组合在一起，要么全部执行成功，要么全部不执行。如果在 Lua 脚本执行过程中出现错误，Redis 会停止脚本的执行，并将错误信息返回给客户端，脚本中已经执行的命令不会被回滚，但后续的命令不会再执行，保证了操作的一致性。\n16.项目中的XXL-JOB是怎么使用的，与Spring Task的区别是什么\n项目中的XXL-JOB主要是定期将社区中的数据进行导出，比如说为了分析网站的运营情况，可以将排行榜数据定时导出，或者将网站的pv&#x2F;uv导出。具体实现方式将会在下面介绍。\nSpring Task：\n轻量级集成：作为 Spring 框架的一部分，无需额外部署，直接通过注解（如 @Scheduled）在 Spring Boot 项目中实现定时任务。\n单机模式：任务调度与业务逻辑耦合在同一应用内，依赖本地线程池执行任务，不支持分布式部署。\nXXL-JOB：\n分布式调度平台：采用「调度中心 + 执行器」架构，支持集群部署。调度中心负责任务管理和触发，执行器独立部署并执行任务逻辑。\n解耦设计：调度中心与执行器通过 HTTP 通信，任务逻辑与调度逻辑分离，便于横向扩展。\n17.为什么使用RabbitMQ\n​\t首先是社区活跃度高，然后 RabbitMQ 还提供了有一个易用的用户界面，可以让用户监控和管理消息，同时我们的系统对并发要求没有那么高，消息通知也可以无序，且 RabbitMQ 也文持消息路由，宕机后的消息也能自动恢复，所以就选择了 RabbitMQ。\n","tags":["Pai-Coding"]},{"title":"动态规划","url":"/2025/04/15/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","content":"​\t最近在做动态规划题的时候时常感到困惑，为什么这个题的边界要初始化，为什么这个题的边界不用初始化，为什么这个两个题明明代码都是一样的初始化的条件却不同，写算法题的时候遇到这种情况真的很痛苦，很想手动模拟，一个一个的算出来对应的值，看一下究竟为什么。但是受限于时间，我先记录对这种情况进行记录，之后慢慢深究。\n首先是LeetCode上的62. 不同路径，这个题我第一遍的时候写了两种做法，两种做法的整体思路都是一样的，但是对应的边界条件不同。代码如下：\n//写法1：public int uniquePaths(int m, int n) &#123;    int[][] f = new int[m][n4];    for(int i = 0; i &lt; m; i ++)&#123;        f[i][0] = 1;    &#125;    for(int j = 0; j &lt; n; j ++)&#123;        f[0][j] = 1;    &#125;    for(int i = 1; i &lt; m; i ++)&#123;        for(int j = 1; j &lt; n; j ++)&#123;            f[i][j] = f[i - 1][j] + f[i][j - 1];        &#125;    &#125;    return f[m - 1][n - 1];&#125;\n\n写法1很好理解，只需要初始化最上边和最右边的所有路径数为1就好，剩下的就是状态转移了。\n//写法2：public int uniquePaths(int m, int n) &#123;    int[][] f = new int[m + 1][n + 1];   \tf[0][1] = 1;    for(int i = 0; i &lt; m; i ++)&#123;        for(int j = 0; j &lt; n; j ++)&#123;            f[i + 1][j + 1] = f[i + 1][j] + f[i][j + 1];        &#125;    &#125;    return f[m][n];&#125;\n\n写法二考虑了边界情况，将动态规划数组初始化为0 -&gt; m和0 -&gt; n，这样i和j就可以从0开始遍历。但是这样带来一个问题，即原二维数组中的(0，0)对应动态规划数组中的(1，1)，因此就不能像写法一中那样进行初始化了，写法二中将f(0，1)初始化为1（也可以将f(1，0）初始化为1，只能初始化一个），f(0，1)对应的是二维数组中(-1，0)，也就是方格外的区域，这样初始化后，在第一次循环的时候会将f(1，1)初始化成1，而f(1，1)对应的是方格中的(0，0)。\n","tags":["动态规划"]},{"title":"XXL-JOB","url":"/2025/04/16/XXL-JOB/","content":""},{"title":"JavaSE","url":"/2025/04/16/JavaSE/","content":"1.反射的原理​\t通常，Java在编译之后，会将Java代码生成为.class文件，JVM启动时，将会载入所有的源文件，并将类型信息存放到方法区中；将所有对象实例存放在Java堆中，同时也会保存指向类型信息的指针。\n​\t正常流程下，我们要创建一个类的实例，是一定确定这个类的类型信息的，我们知道这个类的名字、方法、属性等等。我们可以很容易的创建实例，也可以通过实例很容易的获取属性、调用方法。\n在一个方法中，如果我们不知道在实际运行（runtime）时，它将要处理的对象是谁，它的类型信息是怎么样的，那我们如何访问这个对象或为这个对象创建一个新的实例呢？\n​\t与直接使用类相反，我们需要先获取到对象在方法区的类型信息，获取到类型信息后，我们就知道这个类的构造器、属性、方法、注解、子类、父类等等信息了，这个时候，我们就可以通过这些类型信息来回调处理对象，来完成自己想要的操作了。\n​\t反射的原理：反射在运行时，通过读取方法区中的字节码，来动态的找到其反射的类以及类的方法和属性等（实际上就是在运行时，根据全类型名在方法区找对应的类），用这些类型信息完成对该类实例的操作，其实就是直接使用类的一个逆向使用。\n原文链接：https://blog.csdn.net/HO1_K/article/details/81210947\n","tags":["Java"]},{"title":"设计模式","url":"/2025/04/16/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","content":"1.单例模式确保一个类只有一个实例，并且能够自行实例化向整个系统提供实例。\n//懒汉式（线程不安全）public class LazySingleton &#123;    private static LazySingleton instance;    private LazySingleton() &#123;    &#125;    public static LazySingleton getInstance() &#123;        if (instance == null) &#123;            instance = new LazySingleton();        &#125;        return instance;    &#125;&#125;\n\n//懒汉式（线程安全）public class LazySingleton &#123;    private static LazySingleton instance;    private LazySingleton() &#123;    &#125;    public static synchronized LazySingleton getInstance() &#123;        if (instance == null) &#123;            instance = new LazySingleton();        &#125;        return instance;    &#125;&#125;\n\n//饿汉式public class HungrySingleton &#123;    private static final HungrySingleton instance = new HungrySingleton();    private HungrySingleton()&#123;&#125;        public static HungrySingleton getInstance()&#123;        return instance;    &#125;&#125;\n\n//双重检验锁public class DoubleCheckedLockSingleton &#123;    private volatile static DoubleCheckedLockSingleton instance;    private DoubleCheckedLockSingleton()&#123;&#125;        public static DoubleCheckedLockSingleton getInstance()&#123;        if(instance == null)&#123;            synchronized(DoubleCheckedLockSingleton.class)&#123;                if(instance == null)&#123;                    instance = new DoubleCheckedLockSingleton();                &#125;            &#125;        &#125;        return instance;    &#125;&#125;\n","tags":["八股文"]},{"title":"八股补充","url":"/2025/04/19/%E5%85%AB%E8%82%A1%E8%A1%A5%E5%85%85/","content":"1.NIO的多路复用机制​\tNIO是基于IO多路复用模型的实现，它包含三个核心组件，分别是Buffer、Channel、Sellector。\t1) NIO是面向缓冲区的，在NIO中所有的数据都是通过缓冲区处理的。Buffer就是缓冲区对象，无论读取还是写入，数据都是先进入Buffer的。Buffer的本质是一个数组，通常它是一个字节数组，也可以是其他类型的数组。Buffer是一个接口，它的实现类有ByteBuffer、CharBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer。\t2）Channel是一个通道，可以通过它读取和写入数据。与流不同的是，流是单向的，而Channel是双向的。数据可以通过Channel读到Buffer里，也可以通过Channel写入到Buffer里。为了支持不同的设备，Channel接口有好几种子类，如FileChannel用于访问磁盘文件、SocketChannel和ServerSocketChannel用于TCP协议的网络通信、DatagramChannel用于UDP协议的网络通信。\t3）Selector是多路复用器，可以通过它监听网络IO的状态。它可以不断轮询注册的Channel，如果某Channel上有连接、读取、写入事件发生，则这个Channel就处于就绪状态，就会被Selector轮询出来。所有被轮询出来的Channel集合，我们可以通过SelectionKey获取到，然后进行后续的IO操作。\n2.IO多路复用中select&#x2F;poll&#x2F;epoll各自的实现原理和区别？​\t1）select 使用位图管理 fd，每次调用都需要将 fd 集合从用户态复制到内核态。最大支持 1024 个文件描述符。​\t2）poll 使用动态数组管理 fd，突破了 select 的数量限制。​\t3）epoll 使用红黑树和链表管理 fd，每次调用只需要将 fd 集合从用户态复制到内核态一次，不需要重复复制。\n3.HTTPS 连接过程​\t1）**客户端发起请求：**客户端向服务器发送一个包含 SSL&#x2F;TLS 版本信息、加密算法列表等的握手请求。​\t2）**服务器响应：**服务器收到请求后，返回自己的证书（包含服务器的公钥等信息）、SSL&#x2F;TLS 版本、选择的加密算法等。​\t3）**客户端验证：**客户端验证服务器证书的有效性，如证书是否由可信的证书颁发机构颁发、是否过期等。验证通过后，生成一个随机的预主密钥，用服务器的公钥加密后发送给服务器。​\t4）**密钥交换：**服务器用自己的私钥解密得到预主密钥，然后双方根据预主密钥和之前协商的加密算法，生成会话密钥，用于后续的数据加密传输。​\t5）**数据传输：**客户端和服务器使用会话密钥对数据进行加密和解密，开始安全的数据传输。\n4.MySQL中版本链的回收机制在MySQL中，版本链回收主要与InnoDB存储引擎的多版本并发控制（MVCC）机制相关，其回收机制如下：\n版本链的形成\n\nInnoDB为每行数据记录添加了隐藏的列，包括 DB_TRX_ID （事务ID）和 DB_ROLL_PTR （回滚指针）。当数据被修改时，旧版本的数据会通过回滚指针链接起来，形成版本链。\n\n版本链回收时机\n\n事务提交时：事务提交后，其对数据的修改可能会产生新版本数据，此时会判断该事务产生的旧版本数据是否可以被回收。如果没有其他事务需要访问这些旧版本数据，那么它们就有可能被回收。\n\nPurge操作：MySQL后台有专门的Purge线程，会定期检查并清理不再需要的undo日志以及版本链中的旧数据版本。Purge操作会根据系统中活跃事务的情况，判断哪些版本链上的数据已经不再被任何事务引用，从而将其回收。\n\n\n版本链回收判断条件\n\n系统会通过判断事务的可见性来确定版本链上的数据是否可以被回收。如果一个数据版本的事务ID对于当前所有活跃事务都是不可见的，那么这个数据版本就可以被回收。例如，当一个事务提交后，新的事务看不到该事务修改之前的数据版本，那么这些旧版本数据在满足一定条件下就可以被回收。\n\n空间释放与重用\n\n回收版本链中的数据后，会释放相应的存储空间。这些释放的空间并不会立即返回给操作系统，而是由InnoDB存储引擎管理，用于后续的数据插入或更新操作，以提高存储空间的利用率。\n\n版本链回收机制可以在保证数据一致性和并发访问正确性的前提下，有效地管理存储空间，避免版本链无限增长导致的性能问题和空间浪费。\n"},{"title":"排序算法","url":"/2025/04/18/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","content":""}]