[{"title":"MYDB项目总结","url":"/2025/04/14/MYDB%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/","content":"MYDB1.为什么使用NIO，有哪些好处\n2.日志是怎么做的\n3.如何处理可见性\n​\t1）根据数据库不同的隔离级别来保证不同的可见性\n​\t2）读未提交：这时不对事务的可见性做任何处理，可能会导致脏读、不可重复读、幻读；\n​\t3）读提交：引入MVCC\n​\t\t在读提交隔离级别下如何判断一条记录是否对当前事务可见：​\t\t1）获取当前数据记录的xmin和xmax；\n​\t\t2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n​\t\t3）判断创建该数据记录的事务是否提交，如果已经提交，进一步进行判断，否则说明当前事务为完成，该数据记录对当前事务不可见；\n​\t\t4）如果创建该数据记录的事务已经提交，并且xmax不存在，说明该记录违背删除或者修改，该记录对当前事务可见；\n​\t\t5）如果xmax存在，并且不等于当前事务id，判断xmax事务是否已经提交，若xmax事务还未提交，说明该数据记录对当前版本仍然可见。\n​\t4）读未提交：同样引入MVCC\n​\t\t在可重复读隔离级别下如何判断一条记录是否对当前事务可见：\n​\t\t1）获取当前数据记录的xmin和xmax；\n​\t\t2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n​\t\t3）如果xmin事务已经提交，并且xmin &lt; xid，同时xmin事务已经提交，xmax不存在，说明该数据记录对当前事务可见；\n​\t\t4）如果事务xmax存在，并且xmax不等于xid，如果事务xmax还未提交，或这事务xmax是再当前事务开始后才开始的，又或是事务xmax还处在获活跃状态，说明该数据记录对当前事务是可见的。\n​\t5）串行化：使用两阶段锁，如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。\n4.ACID如何实现\n​\t1）原子性：项目中的事务分为活跃、提交和回滚三个状态，主要是通过对事务状态的保存来确保事务的原子性；\n​\t2）持久性：通过记录日志来保证数据库的持久性，以及事务提交时强制刷盘，保证数据已经写入磁盘中，一次来保证数据库的持久性；\n​\t3）一致性：通过实现其他三种性质来保证一致性；\n​\t4）隔离性：通过数据库中实现的MVCC来保证数据之间的隔离性。\n5.死锁如何处理\n​\t1）当一个事务请求获取某个资源时，首先会检查该资源是否已被其他事务持有。如果没有被持有，资源将直接分配给请求的事务。如果资源已被占用，事务将进入等待状态，并存储在相应的等待队列中。\n​\t2）在某些情况下，事务可能会由于等待时间过长而被回滚。通过后台线程定期检查每个事务的等待时间，并在超时时执行回滚操作。 超时检测与回滚机制的基本思想是：\n\n每个事务在获取资源时，如果资源被其他事务占用，则需要等待。\n为了避免长时间等待导致系统资源被锁住，我们为每个等待的事务设置一个超时时间（30S）。\n当检测到事务等待超时后，系统将回滚这个事务，并释放它占用的所有资源，从而避免死锁或资源饥饿。\n\n启动一个后台线程，定期检查每个事务的等待时间。如果超时，则执行回滚操作。\n6.存储和空间回收如何处理\n​\tMVCC的版本清理：若当前版本的事务ID已提交且无活跃事务引用，则可以清除该版本\n7.介绍下项目中的B+树\n8.SQL语句解析\n​\t1）将SQL语句解析为多个token，其中引号中的内容被当作一个token\n​\t2）根据SQL语句的第一个字段来执行不同的操作\n9.MYDB中锁是如何实现的\n​\tMYDB中的锁是两阶段锁，引入两阶段锁的主要目的是为了让数据库实现可串行化级别的事务隔离。\n​\t串行化（Serializable）：是最高级别的事务隔离，确保事务像是按顺序一个接一个执行的，从而避免了所有的并发问题。在这个级别下，事务之间不会相互影响，彻底解决了脏读、不可重复读和幻读问题。 在 EasyDB 中，串行化通过强制事务之间的完全隔离来实现。在串行化隔离级别下，每个事务只能看到它开始之前已经提交的版本，以及它自己创建或修改的版本。此逻辑与可重复读的一致性逻辑相似。\n​\t两阶段锁：如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。\n\n1.TM (Transaction Manager) 事务管理（1）XID 事务ID，每个事务对应一个ID\n（2）事务状态，active&#x2F;活跃，commited&#x2F;提交，aborted&#x2F;回滚\n（3）文件读写采用NIO，NIO与BIO的对比如下\n​\t\t阻塞与非阻塞\n\nBIO：在进行 I&#x2F;O 操作时，线程会被阻塞。比如在读取数据时，线程会一直等待直到数据完全读取完毕；在写入数据时，会一直等待直到数据全部写入。这种阻塞特性会导致线程在等待过程中无法进行其他工作，造成资源浪费。举例来说，一个服务器使用 BIO 处理多个客户端连接时，每个连接都需要一个独立的线程来处理，若某个客户端连接数据传输缓慢，会使对应线程长时间阻塞，影响系统整体性能。\nNIO：采用非阻塞模式，线程在进行 I&#x2F;O 操作时不会被阻塞，可以去执行其他任务。线程可以询问是否有数据准备好，若没有则可以继续执行其他代码，之后再回来检查。例如，服务器使用 NIO 时，一个线程可以处理多个客户端连接，当某个连接没有数据可读时，线程不会等待，而是去处理其他连接，提高了线程的利用率。\n\n​\t\t多路复用机制\n\nBIO：缺乏有效的多路复用机制，若要处理多个客户端连接，通常需要为每个连接创建一个独立的线程。线程的创建和销毁会带来较大的开销，并且过多的线程会导致系统资源竞争激烈，增加上下文切换的开销，降低系统性能。\nNIO：引入了选择器（Selector），它是 NIO 实现多路复用的核心。一个选择器可以同时监听多个通道（Channel）的事件，如读、写、连接等。线程可以通过选择器来轮询哪些通道有事件发生，然后对这些通道进行相应的处理。这样，一个线程就可以处理多个客户端连接，减少了线程的使用数量，降低了系统开销。\n\n​\t\t缓冲区与通道\n\nBIO：使用流（Stream）的方式进行数据传输，数据的读写是单向的，输入流只能读，输出流只能写。而且流的操作是基于字节或字符的，每次只能处理一个或多个字节 &#x2F; 字符，效率较低。\nNIO：采用缓冲区（Buffer）和通道（Channel）的方式进行数据传输。通道是双向的，可以同时进行读写操作，提高了数据传输的灵活性。缓冲区是一个连续的内存块，数据可以批量地从通道读取到缓冲区，或者从缓冲区写入到通道，减少了数据的复制次数，提高了数据传输的效率。\n\n（4）**begin()**方法，开启一个事务并将其设置为活跃状态，同时事务id计数器自增\n（5）updateXID()方法，更新事务状态，后面的commit() ,**abort()**方法就可以直接借助 updateXID() 方法实现\n（6）检查事务状态的三个方法 isActive(), isCommited(), isAborted()\n（7）静态方法create()，创建一个XID文件\n（8）静态方法open()，从一个已有的XID文件来创建TM\n\n2.DM (Data Manager) 数据管理（1）DM直接管理数据库DB文件和日志文件，具体职责如下：1）分页管理DB文件，并进行缓存；2）管理日志文件，保证数据库在发生错误时根据日志进行恢复；3）抽象DB文件为DataItem，提供给尚存使用，并提供缓存\n（2）引用计数法设计缓存，当计数为0时，直接从缓存中删除这个资源；同时，缓存满了之后应该直接报错。定义了一个抽象类：\nAbstractCache&lt;T&gt;/** * 当资源不在缓存时的获取行为 */protected abstract T getForCache(long key) throws Exception;/** * 当资源被驱逐时的写回行为 */protected abstract void releaseForCache(T obj);\n\n同时，为应对多线程并发场景，额外记录了哪些资源正在被读取，构造了以下三个数据结构：\nprivate HashMap&lt;Long, T&gt; cache;                     // 实际缓存的数据private HashMap&lt;Long, Integer&gt; references;          // 资源的引用个数private HashMap&lt;Long, Boolean&gt; getting;             // 正在被获取的资源\n\n因此在读取缓存时，首先进入死循环，一直尝试从缓存中获取数据，同时检查是否有其他线程正在使用这个数据；\n如果数据在缓存中，直接返回，同时引用计数+1；\n如果不在缓存中，首先在getting中对数据进行标记，表示其正在被使用，在用**getForCache(long key)**获取缓存。\n\n3.数据页的缓存与管理（1）DM向下将文件系统抽象成页面，每次对文件的读写都是以页面为单位的，同时缓存也是以页面为单位进行的，页面缓存存储在内存中。\n（2）数据页大小为8K，借用上一节已经实现的引用计数缓存框架进行缓存，数据页的数据结构如下：\npublic class PageImpl implements Page&#123;\tprivate int pageNumber;\t//页号    private byte[] data;\t//数据内容    private boolean ditry; \t//是否为脏页    private Lock lock;        private PageCache pc;&#125;\n\n（3）获取缓存getForCache(long key)，传入的参数为页号\nprotected Page getForCache(long key) throws Exception &#123;    int pgno = (int)key;    long offset = PageCacheImpl.pageOffset(pgno);    ByteBuffer buf = ByteBuffer.allocate(PAGE_SIZE);    fileLock.lock();    try &#123;        //通过偏移量获取文件开始读写的位置        fc.position(offset);        fc.read(buf);    &#125; catch(IOException e) &#123;        Panic.panic(e);    &#125;    fileLock.unlock();    return new PageImpl(pgno, buf.array(), this);&#125;private static long pageOffset(int pgno) &#123;    // 页号从 1 开始    return (pgno-1) * PAGE_SIZE;&#125;\n\n（4）驱逐页面releaseForCache(Page pg)，\nprotected void releaseForCache(Page pg) &#123;    if(pg.isDirty()) &#123;        flush(pg);        pg.setDirty(false);    &#125;&#125;private void flush(Page pg) &#123;    int pgno = pg.getPageNumber();    long offset = pageOffset(pgno);    fileLock.lock();    try &#123;        //将数据包装成页面        ByteBuffer buf = ByteBuffer.wrap(pg.getData());        //确定读写位置        fc.position(offset);        //写入缓存        fc.write(buf);        //刷回磁盘        fc.force(false);    &#125; catch(IOException e) &#123;        Panic.panic(e);    &#125; finally &#123;        fileLock.unlock();    &#125;&#125;\n\n（5）使用了一个AtomicInteger，记录当前打开的数据库文件有多少页。\n（6）同一条数据不允许跨页存储。\n（7）数据库的第一页用来做启动检查，具体原理是，每次启动数据库的时候，会生成一段随机字节，存储在 100 ~ 107 字节。在数据库正常关闭时，会将这串字节，拷贝到第一页的 108 ~ 115 字节。这样数据库在每次启动时，就会检查第一页两处的字节是否相同，以此来判断上一次是否正常关闭。如果是异常关闭，就需要执行数据的恢复流程。\n（8）对于普通页的管理与第一页不同。普通页面以一个 2字节无符号数开始，表示这一页的空闲指针，在写前读取空闲指针，并在写后更新空闲指针\n（9）**recoverInsert()和recoverUpdate()**用于在数据库崩溃后重新打开，在下一章中会用到\n\n4.日志文件和恢复策略（1）DM每次对数据文件进行操作时，都会记录一条日志到磁盘；数据库崩溃后，再次启动时可以根据日志内容恢复数据文件，保持其一致性。\n日志的二进制文件，按照如下的格式进行排布：\n[XChecksum][Log1][Log2][Log3]...[LogN][BadTail]\n\n其中 XChecksum 是一个四字节的整数，是对后续所有日志计算的校验和。Log1 ~ LogN 是常规的日志数据，BadTail 是在数据库崩溃时，没有来得及写完的日志数据，这个 BadTail 不一定存在。\n（2）每条日志的格式如下：\n[Size][Checksum][Data]\n\n（3）在打开一个日志文件时，需要首先校验日志文件的 XChecksum，并移除文件尾部可能存在的 BadTail，由于 BadTail 该条日志尚未写入完成，文件的校验和也就不会包含该日志的校验和，去掉 BadTail 即可保证日志文件的一致性。\n（4）向日志文件中写入文件时，先写入文件在更新文件的校验和，更新校验和时使用FileChannel的**force()**方法保证文件会被刷回磁盘\n（5）DM向上提供了两种操作：插入和更新，在进行插入和更新前，必须保证日志写入后，才能够对数据进行操作。\n对于两种数据操作，DM 记录的日志如下：\n\n(Ti, I, A, x)，表示事务 Ti 在 A 位置插入了一条数据 x\n(Ti, U, A, oldx, newx)，表示事务 Ti 将 A 位置的数据，从 oldx 更新成 newx\n\n如果不考虑并发的情况，那么在某一时刻，只可能有一个事务在操作数据库。日志会看起来像下面那样：\n(Ti, x, x), ..., (Ti, x, x), (Tj, x, x), ..., (Tj, x, x), (Tk, x, x), ..., (Tk, x, x)\n\n对于单线程，Ti、Tj 和 Tk 的日志永远不会相交。这种情况下利用日志恢复很简单，假设日志中最后一个事务是 Ti：\n\n对 Ti 之前所有的事务的日志，进行重做（redo）\n接着检查 Ti 的状态（XID 文件），如果 Ti 的状态是已完成（包括 committed 和 aborted），就将 Ti 重做，否则进行撤销（undo）\n\n接着，是如何对事务 T 进行 redo：\n\n正序扫描事务 T 的所有日志\n如果日志是插入操作 (Ti, I, A, x)，就将 x 重新插入 A 位置\n如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 newx\n\nundo 也很好理解：\n\n倒序扫描事务 T 的所有日志\n如果日志是插入操作 (Ti, I, A, x)，就将 A 位置的数据删除\n如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 oldx\n\n对于多线程：\n规定1：正在进行的事务，不会读取其他任何未提交的事务产生的数据。\n规定2：正在进行的事务，不会修改其他任何未提交的事务修改或产生的数据。\n\n5.页面索引与DM实现页面索引，缓存了每一页的空闲空间。用于在上层模块进行插入操作时，能够快速找到一个合适空间的页面，而无需从磁盘或者缓存中检查每一个页面的信息。\n\n6.记录的版本&amp;事务隔离（1）两阶段锁：如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。\n​\t2PL 确实保证了调度序列的可串行化，但是不可避免地导致了事务间的相互阻塞，甚至可能导致死锁。为了提高事务处理的效率，降低阻塞概率，实现了 MVCC。\n（2）MVCC：VM(版本管理)管理所有的数据项，并向上层提供数据记录的概念，上层模块通过VM操作数据记录。VM内部为每个数据记录维护了多个版本，每当上层模块对某个数据记录进行修改时，VM就会为这个记录创建一个新的版本。\n（3）一条数据记录中存储的数据格式如下：\n[XMIN] [XMAX] [DATA]\n\n（4）事务的隔离级别：\n读提交：防止级联回滚；实现读提交，为每个版本维护了两个变量，就是上面提到的 XMIN 和 XMAX：\n\nXMIN：创建该版本的事务编号\nXMAX：删除该版本的事务编号\n\nXMIN 应当在版本创建时填写，而 XMAX 则在版本被删除，或者有新版本出现时填写。XMAX 这个变量，也就解释了为什么 DM 层不提供删除操作，当想删除一个版本时，只需要设置其 XMAX，这样，这个版本对每一个 XMAX 之后的事务都是不可见的，也就等价于删除了。\n在读提交隔离级别下如何判断一条记录是否对当前事务可见：1）获取当前数据记录的xmin和xmax；\n2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n3）判断创建该数据记录的事务是否提交，如果已经提交，进一步进行判断，否则说明当前事务为完成，该数据记录对当前事务不可见；\n4）如果创建该数据记录的事务已经提交，并且xmax不存在，说明该记录违背删除或者修改，该记录对当前事务可见；\n5）如果xmax存在，并且不等于当前事务id，判断xmax事务是否已经提交，若xmax事务还未提交，说明该数据记录对当前版本仍然可见。\n可重复读：解决不可重复读的问题，即一个事务执行期间对同一个数据向多次读取得到不同的结果；\n为实现可重复读，规定当前事务运行时需要忽略：1）再本事务后开始的事务所更新的数据，通过比较事务ID实现；\n2）本事务开始时，还是活跃状态事务的数据，通过再当前事务开始时，记录下当前所有活跃的事务ID；重要：如果xmin也在这个活跃事务的集合中，这个数据也应当对当前事务不可见。\n在可重复读隔离级别下如何判断一条记录是否对当前事务可见：\n1）获取当前数据记录的xmin和xmax；\n2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；\n3）如果xmin事务已经提交，并且xmin &lt; xid，同时xmin事务已经提交，xmax不存在，说明该数据记录对当前事务可见；\n4）如果事务xmax存在，并且xmax不等于xid，如果事务xmax还未提交，或这事务xmax是再当前事务开始后才开始的，又或是事务xmax还处在获活跃状态，说明该数据记录对当前事务是可见的。\n\n7.死锁检测与VM实现（1）MVCC 的实现，使得 MYDB 在撤销或是回滚事务很简单：只需要将这个事务标记为 aborted 即可。根据前一章提到的可见性，每个事务都只能看到其他 committed 的事务所产生的数据，一个 aborted 事务产生的数据，就不会对其他事务产生任何影响了，也就相当于，这个事务不曾存在过。\n（2）版本跳跃问题：版本跳跃问题，考虑如下的情况，假设 X 最初只有 x0 版本，T1 和 T2 都是可重复读的隔离级别：\nT1 beginT2 beginR1(X) // T1读取x0R2(X) // T2读取x0U1(X) // T1将X更新到x1T1 commitU2(X) // T2将X更新到x2T2 commit\n\n​\t这种情况实际运行起来是没问题的，但是逻辑上不太正确。T1 将 X 从 x0 更新为了 x1，这是没错的。但是 T2 则是将 X 从 x0 更新成了 x2，跳过了 x1 版本。\n​\t读提交是允许版本跳跃的，而可重复读则是不允许版本跳跃的。解决版本跳跃的思路也很简单：如果 Ti 需要修改 X，而 X 已经被 Ti 不可见的事务 Tj 修改了，那么要求 Ti 回滚。\n​\t事务Ti不可见事务Tj有两种情况：\n​\t1）Ti的事务id小于Tj的事务id，即Tj是在Ti开始后才开始的\n​\t2）事务Ti开始时，Tj仍处于活跃状态\n","tags":["MySQL"]},{"title":"随笔","url":"/2025/04/14/%E9%9A%8F%E7%AC%94/","content":"因为去年电脑重做了系统，博客上的文件并没有存下来，所以今天重新搭建了我的博客。回想22年的时候，YH手把手教我和DL搭建博客，那时候好像在看天书一样，什么都不懂，注册github账号时，少打了一个字母，applepiglet变成了applepiget，也行吧。还是像刚学计算机时一样——你好，世界。\n"},{"title":"技术派项目总结","url":"/2025/04/14/%E6%8A%80%E6%9C%AF%E6%B4%BE%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/","content":"技术派项目总结1.Redis中都缓存了哪些数据\n​\t当前登录的用户id，活跃度排行榜，用户操作数据包括点赞以及阅读量，文章的阅读量，pv&#x2F;uv，作者白名单。\n​\t使用Redis缓存这些数据的好处：提升了用户的访问速度，减少了MySQL的访问频率。\n2.缓存中的数据丢失怎么解决\n​\t对缓存中的数据做了持久化，采用了混合持久化的方式，每次写命令都会将命令同步到AOF文件中。\n通过编辑 Redis 的配置文件 redis.conf 来进行设置，或者在运行时通过 Redis 命令行动态调整。\nRDB 持久化通过在配置文件中设置快照（snapshotting）规则来启用。这些规则定义了在多少秒内如果有多少个键被修改，则自动执行一次持久化操作。\nsave 900 1      # 如果至少有1个键被修改，900秒后自动保存一次save 300 10     # 如果至少有10个键被修改，300秒后自动保存一次save 60 10000   # 如果至少有10000个键被修改，60秒后自动保存一次\n\nAOF 持久化是通过在配置文件中设置 appendonly 参数为 yes 来启用的：\nappendonly yes\n\n此外，还可以配置 AOF 文件的写入频率，这是通过 appendfsync 设置的：\nappendfsync always    # 每次写入数据都同步，保证数据不丢失，但性能较低appendfsync everysec  # 每秒同步一次，折衷方案appendfsync no        # 由操作系统决定何时同步，性能最好，但数据安全性最低\n\n\n\n3.排行榜如何实现\n​\t对用户的操作进行监听，触发更新事件，细节见下面两个问题。\n4.增加或减少活跃度时如何做幂等判断\n​\t一个简单的方案就是将用户的每个加分项，都直接记录下来，在执行具体加分时，基于此来做幂等判定。基于上面这个思路，很容易想到的一个方案就是，每个用户维护一个活跃更新操作历史记录表，我们先尽量设计得轻量级一点。直接将用户的历史日志，保存在redis的hash数据结构中，每天对应一个记录。\n​\t在增加&#x2F;减少活跃度时，首先查询缓存判断是否已经进行过这种操作，如果没有就继续执行，否则直接返回。\nkey: activity_rank_&#123;user_id&#125;_&#123;年月日&#125;\nfield: 活跃度更新key\nvalue: 添加的活跃度\n\n​\t\n5.如何更新排行榜\n​\t首先为了保证活跃度更新时的原子性，使用Redis中zset提供的incr方法对数据进行增减。\n​\t对于用户的操作通过事件监听出发活跃度的更新，Listener代码如下：\n@EventListener(classes = NotifyMsgEvent.class)    @Async    public void notifyMsgListener(NotifyMsgEvent msgEvent) &#123;        switch (msgEvent.getNotifyType()) &#123;            case COMMENT:            case REPLY:                CommentDO comment = (CommentDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setRate(true).setArticleId(comment.getArticleId()));                break;            case COLLECT:                UserFootDO foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setCollect(true).setArticleId(foot.getDocumentId()));                break;            case CANCEL_COLLECT:                foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setCollect(false).setArticleId(foot.getDocumentId()));                break;            case PRAISE:                foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setPraise(true).setArticleId(foot.getDocumentId()));                break;            case CANCEL_PRAISE:                foot = (UserFootDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setPraise(false).setArticleId(foot.getDocumentId()));                break;            case FOLLOW:                UserRelationDO relation = (UserRelationDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setFollow(true).setFollowedUserId(relation.getUserId()));                break;            case CANCEL_FOLLOW:                relation = (UserRelationDO) msgEvent.getContent();                userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setFollow(false).setFollowedUserId(relation.getUserId()));                break;            default:        &#125;    &#125;\n\n​\t此外，用户发布文章也会增加活跃度，额外设置一个Listener，监听文章发布事件，当文章成功发布（状态为Online），出发更新操作，代码如下：\n@Async    @EventListener(ArticleMsgEvent.class)    public void publishArticleListener(ArticleMsgEvent&lt;ArticleDO&gt; event) &#123;        ArticleEventEnum type = event.getType();        if (type == ArticleEventEnum.ONLINE) &#123;            userActivityRankService.addActivityScore(ReqInfoContext.getReqInfo().getUserId(), new ActivityScoreBo().setPublishArticle(true).setArticleId(event.getContent().getId()));        &#125;    &#125;\n\n具体实现细节：\n​\t当监听到用户操作时，Listener首先判断操作类型，然后通过接口userActivityRankService中的addActivityScore方法对用户的活跃读进行增减。\n​\t在真正对分数进行修改前，通过userfoot表（用户足迹表，记录了用户对某篇文章的一系列操作，包括点赞、收藏等）查询用户之前是否进行过这种操作，如果存在记录直接返回，否则进行活跃度的更新。\n6.项目中的JWT时如何实现的\n​\t项目中的JWT token用的长 token，配置了 30 天的有效期，这样用户体验更流畅，不用频繁重新登录。 用户登录成功后，后端将生成的jwt返回给前端，然后前端将其保存在本地缓存；\n​\t之后前端与后端的交互时，都将JWT token放在请求头中，比如可以将其放在Http身份认证的请求头Authorization中，也可以通过自定义的请求头来传递；后端接收到用户的请求，从请求头中获取JWT，然后进行校验，通过之后，才响应相关的接口；否则表示未登录 。\n7.JWT不支持续期，如果用户正在使用中JWT失效了如何解决\n​\t每次用户请求时，如果离过期不远了（比如只剩 5 分钟），就自动生成一个新的 token；返回给前端 → 前端替换旧 token； \n​\t或者用 Redis 设置一个有效期 + TTL（Time To Live，生存时间）滑动延长。用户登录的时候，生成一个 token，将 token 存入 Redis，设置有效期，比如说三十分钟。 用户发起请求时，在拦截器中获取 token，验证其是否在 Redis 中，是否过期。如果有效内，自动延长 30 分钟。 每次请求都延期一下，让 TTL 滑动前进，用户只要活跃就不会掉线。一旦用户长时间不操作，TTL 自动过期，登录状态失效。\n8.从ES中的hits获得了文章id，再去查数据库，性能会提升吗？为什么要用ES而不直接去MySQL里面查\n​\t对于全文检索场景，ES 毫秒级响应（倒排索引），更适合模糊搜索（如文章标题、内容），使用MySQL的LIKE模糊查询速度慢，如果又前缀模糊的情况还会导致全表搜索。复杂条件组合查询（如标签+时间+关键词），ES单次查询效率远高于MySQL多表关联 ，ES专注复杂搜索，MySQL承担事务型操作，符合计算存储分离趋势。可先通过ES筛选符合条件的文章ID，再用MySQL补全未索引字段。\n9.如果这个项目在高并发的场景下，比如很多用户同时点赞评论，应该如何优化？\nRabbitMQ 削峰；\n或者通过令牌桶或漏桶算法限制突发流量，如 RateLimiter；另外，将短时间内的多次点赞合并为一次操作，短时间内同一文章的多条点赞合并为一次INCR操作。\n10.采用自旋锁策略优化缓存结构，针对热key的并发访问进行同步，防止其失效时导致的缓存击穿\n​\t当某个Key失效时，第一个请求发现缓存未命中，尝试通过CAS操作获取锁，其他并发请求在短时间内（如1ms）自旋轮询锁状态，避免线程阻塞和上下文切换开销。获得锁的线程从数据库加载数据并写入缓存，完成后释放锁，其他请求直接从缓存读取。 在业务代码中埋点，针对特定场景（如热门文章、秒杀商品）预标记为热Key。\n11.用户如何进行登录的\n​\t1) 使用用户名和密码进行登录，用户输入用户名和密码，然后到数据库进行校验，如果查询到了记录，返回session放入响应体中，否则返回登录异常信息。用户注册时，对密码进行加盐并进行md5编码存储到数据库中。\n​\t2）微信公众号登录，\n12.项目难点\n​\t1）自定义的雪花算法：时间戳从亳秒改为秒；生成id前五位：年+天；\nworkCenterld:dataCenterld&#x3D;3:7；当时钟回拨时，等待时间追上，而不是直接抛异常。\n​\t**雪花算法缺点：**强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。\n​\t在项目中，并不是每次需要id时，再去调用雪花算法来实时生成;更常见的做法时提前生成好，放在队列中，有需要就从中获取;当队列数据少于某个值时，自动填充id上面这个思路，可以说是将雪花算法 +号段的思想结合起来，应用于业务主键id的生成，最大限度的提高id生成器的可用性以及相应效率。\n​\t针对如果是今天发的文章，但是队列中保存的仍然是昨天的id，如何解决？\n​\t如果出现了跨天的情况，会将队列中的id清空\n2）分布式锁：\t使用Redis 的 setIfAbsent(key,value,time)手动释放锁，但遇到了锁不能及时释放的问题、误释放别人的锁，以及过期时间的设置是否合理等问题。\n​\t导致错误释放别人的锁的原因：\n​\t1）未记录锁的持有者：释放锁时未校验当前锁是否属于自己，直接删除 key。\n​\t2）锁过期与业务处理不同步：业务处理时间超过锁的过期时间，导致锁被提前释放，其他客户端获取到新锁，原客户端仍误认为自己持有锁。\n​\t正确释放方法：\n​\t1）获取锁是携带唯一标识，标识着锁的持有者；\n​\t2）释放锁是，使用Lua脚本原子性的校验并删除锁。\n​\t最后引入 Redission 的看门狗算法进行解决，这样就可以一劳永逸了，不过手动尝试的方式的确也让我对看门狗算法有了一个更深入更直接的了解，它的内部实现也是按照我之前手动的逻辑实现的，起一个定时任务，每 10 秒检查一下锁是否释放，如果没有释放就延长至 30 秒。\n13.项目优化\n14.本地缓存\n​\t引入Caffeine，对页面的侧边栏进行缓存，侧边栏数据变动较少，大多时候都不会改变，能够有效减少访问数据库的次数。\n​\t在**@Cacheable中添加参数cacheManager**指定要使用哪个 CacheManager 来管理缓存操作。要是不指定 cacheManager 属性，Spring 会采用默认的 cacheManager。\n15.Lua脚本为什么能保证原子性\n​\t1）Redis 采用单线程的事件循环机制来处理客户端的请求。这意味着在同一时间，Redis 只能执行一个命令或者一个 Lua 脚本。当一个 Lua 脚本被发送到 Redis 服务器执行时，Redis 会暂停处理其他客户端的请求，直到该 Lua 脚本执行完毕。\n​\t2）Redis 内置了 Lua 解释器，当接收到一个 Lua 脚本时，Redis 会将其加载到内存中并执行。整个脚本的执行过程是连续的，不会被其他命令打断。\n​\t3）在 Redis 中，Lua 脚本可以看作是一种特殊的事务。它将多个 Redis 命令组合在一起，要么全部执行成功，要么全部不执行。如果在 Lua 脚本执行过程中出现错误，Redis 会停止脚本的执行，并将错误信息返回给客户端，脚本中已经执行的命令不会被回滚，但后续的命令不会再执行，保证了操作的一致性。\n16.项目中的XXL-JOB是怎么使用的，与Spring Task的区别是什么\n项目中的XXL-JOB主要是定期将社区中的数据进行导出，比如说为了分析网站的运营情况，可以将排行榜数据定时导出，或者将网站的pv&#x2F;uv导出。具体实现方式将会在下面介绍。\nSpring Task：\n轻量级集成：作为 Spring 框架的一部分，无需额外部署，直接通过注解（如 @Scheduled）在 Spring Boot 项目中实现定时任务。\n单机模式：任务调度与业务逻辑耦合在同一应用内，依赖本地线程池执行任务，不支持分布式部署。\nXXL-JOB：\n分布式调度平台：采用「调度中心 + 执行器」架构，支持集群部署。调度中心负责任务管理和触发，执行器独立部署并执行任务逻辑。\n解耦设计：调度中心与执行器通过 HTTP 通信，任务逻辑与调度逻辑分离，便于横向扩展。\n17.为什么使用RabbitMQ\n​\t首先是社区活跃度高，然后 RabbitMQ 还提供了有一个易用的用户界面，可以让用户监控和管理消息，同时我们的系统对并发要求没有那么高，消息通知也可以无序，且 RabbitMQ 也文持消息路由，宕机后的消息也能自动恢复，所以就选择了 RabbitMQ。\n","tags":["Pai-Coding"]},{"title":"动态规划","url":"/2025/04/15/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","content":"​\t最近在做动态规划题的时候时常感到困惑，为什么这个题的边界要初始化，为什么这个题的边界不用初始化，为什么这个两个题明明代码都是一样的初始化的条件却不同，写算法题的时候遇到这种情况真的很痛苦，很想手动模拟，一个一个的算出来对应的值，看一下究竟为什么。但是受限于时间，我先记录对这种情况进行记录，之后慢慢深究。\n首先是LeetCode上的62. 不同路径，这个题我第一遍的时候写了两种做法，两种做法的整体思路都是一样的，但是对应的边界条件不同。代码如下：\n//写法1：public int uniquePaths(int m, int n) &#123;    int[][] f = new int[m][n4];    for(int i = 0; i &lt; m; i ++)&#123;        f[i][0] = 1;    &#125;    for(int j = 0; j &lt; n; j ++)&#123;        f[0][j] = 1;    &#125;    for(int i = 1; i &lt; m; i ++)&#123;        for(int j = 1; j &lt; n; j ++)&#123;            f[i][j] = f[i - 1][j] + f[i][j - 1];        &#125;    &#125;    return f[m - 1][n - 1];&#125;\n\n写法1很好理解，只需要初始化最上边和最右边的所有路径数为1就好，剩下的就是状态转移了。\n//写法2：public int uniquePaths(int m, int n) &#123;    int[][] f = new int[m + 1][n + 1];   \tf[0][1] = 1;    for(int i = 0; i &lt; m; i ++)&#123;        for(int j = 0; j &lt; n; j ++)&#123;            f[i + 1][j + 1] = f[i + 1][j] + f[i][j + 1];        &#125;    &#125;    return f[m][n];&#125;\n\n写法二考虑了边界情况，将动态规划数组初始化为0 -&gt; m和0 -&gt; n，这样i和j就可以从0开始遍历。但是这样带来一个问题，即原二维数组中的(0，0)对应动态规划数组中的(1，1)，因此就不能像写法一中那样进行初始化了，写法二中将f(0，1)初始化为1（也可以将f(1，0）初始化为1，只能初始化一个），f(0，1)对应的是二维数组中(-1，0)，也就是方格外的区域，这样初始化后，在第一次循环的时候会将f(1，1)初始化成1，而f(1，1)对应的是方格中的(0，0)。\n","tags":["动态规划"]},{"title":"XXL-JOB","url":"/2025/04/16/XXL-JOB/","content":""},{"title":"JavaSE","url":"/2025/04/16/JavaSE/","content":"1.反射的原理​\t通常，Java在编译之后，会将Java代码生成为.class文件，JVM启动时，将会载入所有的源文件，并将类型信息存放到方法区中；将所有对象实例存放在Java堆中，同时也会保存指向类型信息的指针。\n​\t正常流程下，我们要创建一个类的实例，是一定确定这个类的类型信息的，我们知道这个类的名字、方法、属性等等。我们可以很容易的创建实例，也可以通过实例很容易的获取属性、调用方法。\n在一个方法中，如果我们不知道在实际运行（runtime）时，它将要处理的对象是谁，它的类型信息是怎么样的，那我们如何访问这个对象或为这个对象创建一个新的实例呢？\n​\t与直接使用类相反，我们需要先获取到对象在方法区的类型信息，获取到类型信息后，我们就知道这个类的构造器、属性、方法、注解、子类、父类等等信息了，这个时候，我们就可以通过这些类型信息来回调处理对象，来完成自己想要的操作了。\n​\t反射的原理：反射在运行时，通过读取方法区中的字节码，来动态的找到其反射的类以及类的方法和属性等（实际上就是在运行时，根据全类型名在方法区找对应的类），用这些类型信息完成对该类实例的操作，其实就是直接使用类的一个逆向使用。\n原文链接：https://blog.csdn.net/HO1_K/article/details/81210947\n","tags":["Java"]},{"title":"设计模式","url":"/2025/04/16/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","content":"1.单例模式确保一个类只有一个实例，并且能够自行实例化向整个系统提供实例。\n//懒汉式（线程不安全）public class LazySingleton &#123;    private static LazySingleton instance;    private LazySingleton() &#123;    &#125;    public static LazySingleton getInstance() &#123;        if (instance == null) &#123;            instance = new LazySingleton();        &#125;        return instance;    &#125;&#125;\n\n//懒汉式（线程安全）public class LazySingleton &#123;    private static LazySingleton instance;    private LazySingleton() &#123;    &#125;    public static synchronized LazySingleton getInstance() &#123;        if (instance == null) &#123;            instance = new LazySingleton();        &#125;        return instance;    &#125;&#125;\n\n//饿汉式public class HungrySingleton &#123;    private static final HungrySingleton instance = new HungrySingleton();    private HungrySingleton()&#123;&#125;        public static HungrySingleton getInstance()&#123;        return instance;    &#125;&#125;\n\n//双重检验锁public class DoubleCheckedLockSingleton &#123;    private volatile static DoubleCheckedLockSingleton instance;    private DoubleCheckedLockSingleton()&#123;&#125;        public static DoubleCheckedLockSingleton getInstance()&#123;        if(instance == null)&#123;            synchronized(DoubleCheckedLockSingleton.class)&#123;                if(instance == null)&#123;                    instance = new DoubleCheckedLockSingleton();                &#125;            &#125;        &#125;        return instance;    &#125;&#125;\n","tags":["八股文"]},{"title":"八股补充","url":"/2025/04/19/%E5%85%AB%E8%82%A1%E8%A1%A5%E5%85%85/","content":"1.NIO的多路复用机制​\tNIO是基于IO多路复用模型的实现，它包含三个核心组件，分别是Buffer、Channel、Sellector。​\t1) NIO是面向缓冲区的，在NIO中所有的数据都是通过缓冲区处理的。Buffer就是缓冲区对象，无论读取还是写入，数据都是先进入Buffer的。Buffer的本质是一个数组，通常它是一个字节数组，也可以是其他类型的数组。Buffer是一个接口，它的实现类有ByteBuffer、CharBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer。​\t2）Channel是一个通道，可以通过它读取和写入数据。与流不同的是，流是单向的，而Channel是双向的。数据可以通过Channel读到Buffer里，也可以通过Channel写入到Buffer里。为了支持不同的设备，Channel接口有好几种子类，如FileChannel用于访问磁盘文件、SocketChannel和ServerSocketChannel用于TCP协议的网络通信、DatagramChannel用于UDP协议的网络通信。​\t3）Selector是多路复用器，可以通过它监听网络IO的状态。它可以不断轮询注册的Channel，如果某Channel上有连接、读取、写入事件发生，则这个Channel就处于就绪状态，就会被Selector轮询出来。所有被轮询出来的Channel集合，我们可以通过SelectionKey获取到，然后进行后续的IO操作。\n2.IO多路复用中select&#x2F;poll&#x2F;epoll各自的实现原理和区别？​\t1）select 使用位图管理 fd，每次调用都需要将 fd 集合从用户态复制到内核态。最大支持 1024 个文件描述符。​\t2）poll 使用动态数组管理 fd，突破了 select 的数量限制。​\t3）epoll 使用红黑树和链表管理 fd，每次调用只需要将 fd 集合从用户态复制到内核态一次，不需要重复复制。\n3.HTTPS 连接过程​\t1）**客户端发起请求：**客户端向服务器发送一个包含 SSL&#x2F;TLS 版本信息、加密算法列表等的握手请求。​\t2）**服务器响应：**服务器收到请求后，返回自己的证书（包含服务器的公钥等信息）、SSL&#x2F;TLS 版本、选择的加密算法等。​\t3）**客户端验证：**客户端验证服务器证书的有效性，如证书是否由可信的证书颁发机构颁发、是否过期等。验证通过后，生成一个随机的预主密钥，用服务器的公钥加密后发送给服务器。​\t4）**密钥交换：**服务器用自己的私钥解密得到预主密钥，然后双方根据预主密钥和之前协商的加密算法，生成会话密钥，用于后续的数据加密传输。​\t5）**数据传输：**客户端和服务器使用会话密钥对数据进行加密和解密，开始安全的数据传输。\n4.MySQL中版本链的回收机制在MySQL中，版本链回收主要与InnoDB存储引擎的多版本并发控制（MVCC）机制相关，其回收机制如下：\n版本链的形成\n\nInnoDB为每行数据记录添加了隐藏的列，包括 DB_TRX_ID （事务ID）和 DB_ROLL_PTR （回滚指针）。当数据被修改时，旧版本的数据会通过回滚指针链接起来，形成版本链。\n\n版本链回收时机\n\n事务提交时：事务提交后，其对数据的修改可能会产生新版本数据，此时会判断该事务产生的旧版本数据是否可以被回收。如果没有其他事务需要访问这些旧版本数据，那么它们就有可能被回收。\n\nPurge操作：MySQL后台有专门的Purge线程，会定期检查并清理不再需要的undo日志以及版本链中的旧数据版本。Purge操作会根据系统中活跃事务的情况，判断哪些版本链上的数据已经不再被任何事务引用，从而将其回收。\n\n\n版本链回收判断条件\n\n系统会通过判断事务的可见性来确定版本链上的数据是否可以被回收。如果一个数据版本的事务ID对于当前所有活跃事务都是不可见的，那么这个数据版本就可以被回收。例如，当一个事务提交后，新的事务看不到该事务修改之前的数据版本，那么这些旧版本数据在满足一定条件下就可以被回收。\n\n空间释放与重用\n\n回收版本链中的数据后，会释放相应的存储空间。这些释放的空间并不会立即返回给操作系统，而是由InnoDB存储引擎管理，用于后续的数据插入或更新操作，以提高存储空间的利用率。\n\n版本链回收机制可以在保证数据一致性和并发访问正确性的前提下，有效地管理存储空间，避免版本链无限增长导致的性能问题和空间浪费。\n5.如何排查MySQL的死锁\n​\tMySQL的InnoDB实现了行级别锁：共享锁（S Lock）和排他锁（X Lock）\n6.对 MySQL 进行增删改时 B + 树的变化\n插入操作\n叶子节点空间充足：当插入一条新记录时，首先根据索引键值找到对应的叶子节点。如果该叶子节点还有足够的空间来存储新记录，就直接将新记录插入到叶子节点的合适位置，并保持节点内键值的有序性。\n叶子节点空间已满：若叶子节点已满，就需要进行节点分裂操作。具体做法是将该叶子节点分裂成两个新的叶子节点，把原节点中的键值平均分配到两个新节点中，同时将中间的键值提升到父节点中。如果父节点也因此满了，就继续向上分裂，直到根节点。若根节点分裂，会创建一个新的根节点。\n\n删除操作\n叶子节点删除后仍满足最小填充要求：删除记录时，先找到对应的叶子节点并删除该记录。如果删除后叶子节点中的键值数量仍然满足最小填充要求（通常是节点最大容量的一半），则不需要进行其他操作。\n叶子节点删除后不满足最小填充要求：若删除后叶子节点的键值数量低于最小填充要求，就需要进行节点合并或重新分配操作。可以尝试从相邻的兄弟节点借一个键值，或者将该叶子节点与相邻的兄弟节点合并。如果合并操作导致父节点的键值数量低于最小填充要求，就继续向上处理，可能会引发父节点的合并或重新分配，甚至可能会导致树的高度降低。\n\n修改操作\n键值不变：如果修改操作不改变索引键值，只需要更新叶子节点中对应记录的其他字段即可。\n键值改变：若修改操作改变了索引键值，相当于先删除原记录，再插入新记录。需要根据新的键值找到合适的叶子节点进行插入操作，同时删除原记录所在的位置。这可能会触发节点的分裂、合并或重新分配等操作。\n\n7.Insert一条数据会加什么锁前提\nInnoDB 默认规则\n有索引（主键 &#x2F; 唯一键 &#x2F; 普通索引）时，用 行级锁（只锁一行或相关索引）；\n无索引时，只能用 表级锁（锁整张表，阻塞所有人读写）。\n\n隔离级别影响\n读已提交（RC）：几乎不加间隙锁（简单场景只锁一行）；\n可重复读（RR，默认）：可能加间隙锁（防止插入导致的幻读，但 Insert 会尽量优化）。\n\n\n场景 1：插入到主键 &#x2F; 唯一索引-- 表结构：id是主键（唯一索引）CREATE TABLE t(id INT PRIMARY KEY, name VARCHAR(10));-- 插入语句：INSERT INTO t(id, name) VALUES (1, &#x27;a&#x27;);\n\n\n记录锁（行锁）：锁定主键索引中 id=1 这一行（X 锁，排他锁），阻止别人修改 &#x2F; 删除这一行；\n\n插入意向锁在插入前，检查id&#x3D;1前后是否有间隙（比如前一个是 0，后一个是 2，间隙是 (0,2)），加一个轻量级锁，告诉别人 “我要在这里插入”。\n重点：插入意向锁不阻塞其他插入（比如另一个事务插入 id&#x3D;3，没问题），只阻塞想在同间隙插入唯一键冲突的操作。\n\n\n\n结论：主键 &#x2F; 唯一索引插入时，只锁当前行，间隙锁几乎不影响并发。\n\n场景 2：插入到非索引列（比如 name 字段无索引）-- name字段没有索引INSERT INTO t(id, name) VALUES (2, &#x27;b&#x27;);\n\nInnoDB 找不到 name 的索引，只能通过主键 id&#x3D;2 定位数据，所以：\n\n只锁主键索引的 id&#x3D;2 这一行（X 记录锁），和场景 1 一样；\nname 字段无索引，所以不会对 name 加锁（因为无法通过 name 快速定位，只能全表扫描，所以锁在主键上）。\n\n\n结论：非索引列插入，锁还是加在主键上，和普通主键插入一样。\n\n场景 3：插入重复唯一键（比如主键已存在）-- 已有id=1，再次插入id=1INSERT INTO t(id, name) VALUES (1, &#x27;b&#x27;);\n\n\n先检查主键唯一性，发现 id&#x3D;1 已存在，对 id&#x3D;1 这一行加 X 记录锁（防止其他事务同时修改这个 id）；\n发现冲突后，报错回滚，释放锁。\n\n\n结论：唯一性检查会锁冲突行，阻止并发插入相同值。\n\n场景 4：表中没有任何索引（极端情况）-- 无索引表（InnoDB会自动加隐藏主键，但用户无索引）CREATE TABLE no_index (data VARCHAR(100));INSERT INTO no_index VALUES (&#x27;a&#x27;);\n\n无索引时，InnoDB 无法用行级锁，只能加表级锁（IX 锁，意向排他锁）\n\n插入时锁定整张表，阻塞其他事务的所有写操作（读可能允许，取决于隔离级别）；\n性能极差，并发插入会排队。\n\n\n结论：无索引表插入 &#x3D; 表锁\n\n"},{"title":"排序算法","url":"/2025/04/18/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","content":""},{"title":"测试","url":"/2025/04/21/%E6%B5%8B%E8%AF%95/","content":"1.黑盒测试&amp;白盒测试测试角度\n黑盒测试：从用户角度出发，将软件视为一个黑盒子，不考虑内部结构和实现细节，只关注软件的输入输出和功能表现。\n白盒测试：从开发人员角度出发，对软件的内部结构、代码逻辑、程序路径等进行测试，了解软件的内部工作原理。\n\n测试方法\n黑盒测试：主要运用等价类划分、边界值分析、决策表、因果图等方法，通过输入不同的测试数据，检查软件的功能是否符合需求规格说明书的要求。\n白盒测试：采用逻辑覆盖（如语句覆盖、判定覆盖、条件覆盖等）、路径覆盖等方法，设计测试用例来覆盖软件的内部逻辑和代码路径。\n\n测试重点\n黑盒测试：重点在于发现软件功能上的错误、遗漏或缺陷，验证软件是否满足用户的需求，包括功能的正确性、完整性、易用性等方面。\n白盒测试：主要关注软件内部的代码结构和逻辑流程，检查代码的规范性、可读性、可维护性，以及是否存在逻辑错误、代码漏洞等。\n\n测试用例设计依据\n黑盒测试：依据软件的需求规格说明书、用户手册等文档，根据用户的使用场景和功能需求来设计测试用例。\n白盒测试：依据软件的源代码、详细设计文档等，根据代码的逻辑结构和控制流程来设计测试用例。\n\n适用场景\n黑盒测试：适用于软件的各个阶段，尤其是在需求明确、功能稳定的情况下，能够有效地验证软件的功能是否符合要求，常用于验收测试、系统测试等。\n白盒测试：通常在软件开发的早期阶段，如单元测试、集成测试中使用，有助于开发人员在编写代码时及时发现和纠正错误，提高代码质量。\n\n2.性能测试应该关注哪些指标​\t性能测试是确保系统在不同负载和压力下稳定运行的关键环节，需要关注以下核心指标以全面评估系统性能：\n1.响应时间（Response Time）\n\n定义：从用户发起请求到系统完成响应的总时间。\n网络延迟：数据传输时间。\n处理时间：服务器计算、数据库查询等耗时。\n客户端渲染时间：浏览器解析和渲染页面的时间。\n\n\n重要性：直接影响用户体验，通常需满足业务要求（如API响应≤500ms）。\n\n\n2. 吞吐量（Throughput）\n定义：单位时间内系统处理的请求数量。\nTPS（Transactions Per Second）：每秒事务数，适用于业务场景（如支付）。\nQPS（Queries Per Second）：每秒查询数，适用于高频读写场景（如数据库）。\n\n\n重要性：衡量系统处理能力，高吞吐量通常代表高效资源利用。\n\n\n3. 资源利用率\nCPU：监控使用率、负载及热点进程，过载可能导致性能瓶颈。\n内存：关注使用量、泄漏（长期运行后内存增长）及交换（Swap）情况。\n磁盘I&#x2F;O：读写速度、磁盘队列长度，高延迟可能拖慢系统。\n网络带宽：流量峰值、连接数，避免网络成为瓶颈。\n数据库连接池：活跃连接数、等待时间，连接泄漏会引发性能下降。\n\n\n4. 并发用户数\n实际并发：真实用户同时操作的数量。\n模拟并发：通过工具（如JMeter）模拟的虚拟用户数。\n关键点：观察系统在并发下的表现，如线程竞争、数据库锁争用等问题。\n\n\n5. 错误率（Error Rate）\nHTTP错误：如5xx（服务端错误）、4xx（客户端错误）。\n业务错误：如支付失败、数据不一致。\n重要性：高错误率可能表明资源不足、代码缺陷或配置问题。\n\n\n6. 可扩展性（Scalability）\n垂直扩展：单机资源（如CPU、内存）增加后的性能提升。\n水平扩展：增加节点后的性能线性增长能力。\n测试方法：逐步增加资源，观察性能提升是否符合预期。\n\n\n7. 稳定性（Stability）\n疲劳测试：长时间运行（如24小时）后性能是否下降。\n关键指标：内存泄漏、资源耗尽（如文件句柄）、线程阻塞等。\n\n\n8. 用户体验指标\n首次内容渲染（FCP）：用户首次看到页面内容的时间。\n最大内容渲染（LCP）：页面主要内容的加载时间。\n累积布局偏移（CLS）：页面元素是否动态变化导致视觉不稳定。\n\n\n9. 系统容量（Capacity）\n最大承载量：系统在可接受响应时间内能支持的最大并发用户&#x2F;请求量。\n阈值设定：为扩容或优化提供依据（如电商大促前预估峰值）。\n\n\n10. 业务指标\n成功率：如订单提交成功率、支付成功率。\n一致性：分布式系统中数据最终一致性的达成时间。\n\n\n其他专项指标\n缓存命中率：缓存有效减少数据库压力的程度。\n数据库指标：慢查询比例、锁等待时间、索引效率。\n网络指标：延迟（Ping）、丢包率、TCP重传次数。\n\n\n不同测试类型的侧重点\n\n\n测试类型\n关注指标\n\n\n\n负载测试\n最大吞吐量、响应时间随负载的变化趋势\n\n\n压力测试\n系统崩溃点、错误率激增时的资源状态\n\n\n容量测试\n确定资源需求（如CPU&#x2F;内存&#x2F;磁盘）\n\n\n疲劳测试\n长时间运行下的稳定性、内存泄漏\n\n\n3.测试用例1.基本功能测试2.兼容性测试3.性能测试4.异常情况测试5.易用性测试4.软件测试的阶段划分1. 单元测试（Unit Testing）\n目标：验证单个模块或组件的功能是否符合设计要求。\n阶段：开发阶段完成后，由开发人员主导。\n策略：\n白盒测试：基于代码逻辑设计测试用例，覆盖分支、边界条件等。\n自动化工具：使用JUnit、pytest等框架，结合持续集成（CI）工具（如Jenkins）。\n\n\n要求：\n测试用例覆盖所有代码路径（如if-else分支、循环）。\n验证模块的输入输出是否符合预期。\n代码覆盖率需达到一定标准（如80%以上）。\n\n\n示例：测试一个计算加法的函数，输入不同边界值（如负数、零、大数）。\n\n\n2. 集成测试（Integration Testing）\n目标：验证多个模块组合后的交互是否正常，接口是否兼容。\n阶段：单元测试后，由测试团队或开发人员协同完成。\n策略：\n自顶向下：从顶层模块开始，逐步集成底层模块。\n自底向上：先测试底层模块，逐步向上集成。\n增量集成：逐个添加模块，持续验证接口。\n\n\n要求：\n使用工具（如Postman）测试API接口的连通性和数据一致性。\n模拟模块间的数据传递，检查依赖关系（如数据库连接）。\n解决模块间接口的冲突或数据格式错误。\n\n\n示例：测试用户登录模块与权限管理模块的集成，验证登录成功后权限是否正确生效。\n\n\n3. 系统测试（System Testing）\n目标：验证整个系统是否满足需求规格说明书的要求。\n阶段：集成测试后，由独立测试团队执行。\n策略：\n黑盒测试：基于用户需求设计测试用例，不关注内部代码。\n多维度覆盖：\n功能测试：验证所有业务场景（如支付、搜索）。\n性能测试：检查响应时间、吞吐量、并发能力。\n安全测试：渗透测试、漏洞扫描（如SQL注入）。\n兼容性测试：不同浏览器、操作系统、设备上的表现。\n\n\n\n\n要求：\n测试环境需与生产环境一致（如相同的服务器配置）。\n测试用例需覆盖正向、逆向和异常操作。\n生成详细的测试报告，记录缺陷并跟踪修复。\n\n\n示例：模拟1000用户同时下单，验证系统是否崩溃或响应延迟。\n\n\n4. 验收测试（Acceptance Testing）\n目标：确认系统是否满足用户需求，是否可正式交付。\n阶段：系统测试后，由客户或最终用户参与。\n策略：\nAlpha测试：内部用户模拟真实场景，发现问题后修复。\nBeta测试：发布给外部用户，收集反馈并优化。\nUAT（用户验收测试）：用户按实际业务流程操作，确认功能可用性。\n\n\n要求：\n测试场景需覆盖核心业务和高频操作。\n用户需签署验收报告，确认系统符合合同要求。\n修复验收阶段发现的缺陷，否则可能导致项目延期。\n\n\n示例：电商系统上线前，邀请真实用户完成商品浏览、下单、支付全流程测试。\n\n\n5. 回归测试（Regression Testing）\n目标：验证代码变更后原有功能是否正常。\n阶段：每次迭代或修复缺陷后执行。\n策略：\n自动化回归：使用Selenium、TestNG等工具执行重复用例。\n增量覆盖：仅测试受变更影响的模块及相关联功能。\n\n\n要求：\n回归用例库需持续维护，避免冗余。\n优先执行核心功能的测试用例。\n结合持续集成（CI），确保每次提交代码后自动触发回归测试。\n\n\n示例：修复订单支付模块的漏洞后，重新测试支付流程及关联的库存扣减功能。\n\n","tags":["软件测试"]}]